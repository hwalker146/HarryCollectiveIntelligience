# a16z Podcast - Master Transcripts

**Generated:** 2025-08-15 16:12:12
**Total Episodes:** 5

Episodes organized by publication date (newest first).

---

## 2025-08-15

### The State of American AI Policy: From ‘Pause AI’ to ‘Build’
**Publication Date:** 2025-08-15T10:00:00
**Episode ID:** 5078

**Full Transcript:**
So we've been through all of these tech waves and we've learned how to have this discussion in a way that, for the United States' interest, balances these two things. And if we're going to make a departure from a posture that was developed from 40 years, we better have a pretty damn good reason. Today, a new frontier of scientific discovery lies before us. You can sometimes judge a book by its cover, and I think this is a strong start. The conversation around AI regulation in the U.S. has changed dramatically. Just a year ago, the loudest voices were calling to pause or shut down open source AI. Today, the U.S. is pushing to lead the global race. So what changed? And what does it mean for innovation, competition, and the future of open source? I'm joined by A16Z General Partners Martin Casado and Anjane Mithra to unpack the new AI action plan, the politics behind it, and the implications for builders and policymakers alike. Let's get into it. As a reminder, the content here is for informational purposes only, should not be taken as legal business, tax, or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund. Please note that A16Z and its affiliates may also maintain investments in the companies discussed in this podcast. For more details, including a link to our investments, please see a16z.com forward slash Okay, so we're talking a week or two after the action plan has been announced. Looks like we've come a long way. Yeah, you guys have been on the front lines for years now in this discourse, fighting to make this possible. Why don't we trace where we've been so that we could then understand how we got here and where we're going. I mean, under the Biden administration, we had the executive order, which was basically the opposite of what we're seeing today. I mean, it was trying to limit innovation. It was doing a bunch of fear mongering. But to me, what was even more striking was not regulators being regulators. You'd expect that. But if you remember, Anj, and this is why we got involved, is you'd have these politicians making recommendations, which is fine, you'd expect that. But nobody was saying anything. It was like academia was silent, the startups were silent, and if anything, the technologists were kind of supporting it. So we were in the super backwards world where it was like innovation is bad or dangerous and we should regulate it, we should pause it. You know, there was this discourse and it was like somewhat fueled by tech as opposed, you know, and then nobody was going against it. And so I think today we should definitely talk about the action plan is great, but we should also talk about how the entire industry has kind of come around to say like, listen, we need to keep these things in check. We need to be sensible. Yeah. I mean, pause AI. That was two years ago. I remember the big sort of, you know, all the CEOs signed this petition. Oh, yeah. And I think that was the last AI Action Summit, right? The one before Paris. There's been so many of these. Yeah, I must try. I must try. No, no. Remember, like, what was the Dan Hendricks' CAIS? What was California AI? The Center for AI Safety. Center for AI Safety. That's it. That's the nonprofit. Yeah. Yeah. And I remember, like, people to sign this list, you know, like, when you need to worry about the existential risk of AI, and like, that was the mood. It was almost like, but can I just do something by contrast, right? So I was, you know, there during kind of like the early days of the web and the Internet. And at that time, you actually had examples of the stuff being dangerous, right? Like Robert Morris, like, let out the Morris worm. It took down critical infrastructure we had. So we had new types of attacks. We had viruses. We had worms. We had critical infrastructure. We actually had a different doctrine for the nation, which said, you know, the more we get on the Internet, the more vulnerable we are. So instead of, like, mutually assured destruction, we have this notion of asymmetry. So there was all of these great examples of why should we be concerned? And what did everybody else do? Pedal to the metal, invest more technology. This is great. And so, like, you know, we were still at the time, like, we wanted the Internet. We wanted to be the best. We wanted to build it out. You know, the startups were all over it. And coming into this AI stuff two years ago, it was the opposite, which is like there were the concerns with new technology, which you always have. But like there are very few voices that were like, actually, it's really important we invest in this stuff. And so that's kind of, to me, the bigger change is this more cultural change. I think that's right. There was a moment in, I think it was last summer, where somebody sent you and me a link to the SB1047 bill. And I remember Marty and I reacting like, there's no way this is going to get any steam. What was absurd to us, I think, was that it made it through the House and the Senate and it was on its way to a final vote and would have become law, one signature from the governor later. And I think there was this escalation where I realized, I think my view is that technologists like to technology and politicians like to policy and to pretend like these two things are in different worlds. And as long as these two worlds don't collide and the engineers get to, like, build interesting tech and there's no sort of, like, self-own to Erlene, we generally trust in our policymakers. And that changed completely, I think, last summer, which is a really weird cultural shift, which is, no, no, no. A lot of policymakers who actually, I think, were quite open about the fact they didn't know much about the technology because it was moving so fast, still felt like something had to be done. Therefore, this is something, therefore it must be good. And that this was this, I think the most egregious example of this being adversarial was SB1047. I totally agree. But that culture shift was one from, let's let the tech mature and then decide how to regulate it later to, like, before let's try to regulate it in its infancy was like a massive, I think, shift in my head. But let's just talk about how bad it was. You had VCs. Their entire job is investing in tech, talking against open source, you know, like Vinode, Founders Fund. They're like, open source AI is dangerous. It gives China the advantage. And there was just some sort of prognostication that if we didn't do open AI, like the Chinese would somehow forget math and not be able to create models. And then you forward by a year and they've got the best models by far and we're way behind. So it was like the people that are supposed to be protecting the U.S. innovation brain trust were somehow on the side of the let's slow it down. And I think that now there's this realization of China's really good at creating models and they've done a great job. We've kind of hamstrung ourselves from whatever discussion we were having. And I think you're right. I think it's good to be concerned about the dangers and job risks, but it has to be a fulsome discussion. You need both sides. And when you and I jumped in, it just didn't feel fulsome at all. It was like one side was dominant and there was almost no one on kind of the pro-tech, pro-innovation, pro-open source side. I just think it didn't feel grounded in empirics, right? Certainly not that. It came from, you know. What is the steel man of the critique of open source that they were making a couple of years ago? That, you know, this is like a nuclear weapon. Would you open source your nuclear weapon plans? Would you open source your F-16 plans? So the idea was that somehow like this was like, you know, nuclear weapons are not dual use. Nuclear energy is dual use. Right. An F-16 is not dual use like a jet engine is dual use. But a lot of the analogies that were used at the time were something that, you know, if you squint one way, parts of it are dual use. They could be used for good or for bad, but like the examples were clearly the weapons. And that's what they would say. They would say, listen, these things are incredibly dangerous. Would you open source like whatever the plans for an F-16? And then, you know, the other side would slowly decided like this conversation is ridiculous. We got to go ahead and set up. It says, you know, no, you would not do this for an F-16 because that is a fighter, you know, jet. However, like a lot of the technologies used to build it. This is, you know, fundamental. It's not like people aren't going to figure out any ways and we need to be the leader just like we were the leader in nuclear. And we were then, by the way, in nuclear, like if you go historically, when that came out, we invested incredibly heavily in it. The things that we thought were proximal to weapons, of course, we made sensitive, you know, but this, you know, all the universities were involved, like the entire country had the discourse and that just wasn't what was happening. I think that's true. They were basically like there was a substantive argument against open source and there was an atmospheric one. And the substantive one was like the one Martin mentioned, that the technology was being confused for the applications, right? And all the worst case outcomes of the applications or misuses were then being confused. But they were also theoretical too. It's even worse than that. It was like, you're right in what you're saying, but it was like, this could potentially create bioweapons. It's funny. We got a bioweapon expert. He's like, well, not really. I mean, like the difference between like a model in Google is almost nothing. But, you know, like that was used as this, you know, straw person argument and then it could hack into a whole bunch of stuff like nobody had ever done it before, but it was theoretical. So it was like these theoretical arguments that were very specific versus a broad technology. That was one. And then the atmospherics, there was a famous former CEO who went up in front of Congress and literally in a testimony said, the U.S. is years ahead of China. And so since these are nuclear weapons and that misuses were being confused with the technology and we're so far ahead, let's lock it down so we can maintain that lead. And therefore our adversaries will never get their hands on it, which were both just fundamentally wrong. For the reason Martin said, like substantively, AI was not introducing new marginal risks. So if you did an eval on how much easier it is. Well, at least not identified at the time. You would go to Don Song, who is like a safety researcher, McCarthy genius fellow at Berkeley, and you'd say, what are the marginal risks of AI? She'd say, great question. We should research that. That should be a good research problem, yeah. No other world expert on this question was like, this is a very important, but it's an open research statement. Yeah. So, so, so no empirical evidence at the time that AI was creating net new marginal risks and just factual inaccuracies that we were ahead of China, because if you just paid attention to what was happening, DeepSeek had already started to publish a fantastic set of papers, including DeepSeek Math V2, which came out last summer. And you're like, OK, obviously these guys are clearly close to the frontier. They're not years behind. And so when R1, DeepSeek R1 came out earlier this year, you know, a lot of Washington was like shocked. Oh my God. They're like, how did these folks catch it? They must have stolen our way. It's like, no, actually, it's not that hard to distill on the outputs of our labs. Have you actually looked at the author list of any paper in AI? Like where do you think these people come from? So I think those two things were, it felt like we were being gaslit constantly because both the content and the atmosphere were just wrong. Maybe one question for the smartest people or the most sober people who were against it is like, maybe they were asking, where should the burden of proof be? Because it's hard to prove that there is risk, but it's also hard to prove that there isn't risk. And so this question of what's risky, is it riskier to just go full steam ahead or is it riskier to kind of slow down until we better understand sort of these models, you know, interpretability, et cetera. I mean, I think it's really important to ground these hypothetical discussions on what we've learned as an industry. I mean, the discourse around tech safety has been around for 40 years. So we went through it with compute. And like, remember when we're like, okay, Saddam Hussein shouldn't have PlayStations because you can use GPUs to simulate nuclear weapons. That was actually a pretty robust and real discussion, but that did not stop, you know, us from having other people create chips or video games. Right. I mean, we went through the internet, we went through the cloud, we went through mobile. And so we've been through all of these tech waves and we've learned how to have this discussion in a way that for the United States interest balances these two things. And, you know, listen, we've had kind of areas that were very sensitive to national governance. Think about like Huawei and Cisco, for example, and we as a nation did start to put in kind of import and export restrictions as a result. And so I just feel these almost platonic, you know, polemic questions like the one that you just posed aren't rooted in 40 years of learning. So all I ask is, if we're going to make a departure from a posture that was developed from 40 years, we better have a pretty damn good reason. And if we don't have a good reason, then I think we should probably learn from that experience. Yeah, I think extraordinary claims require extraordinary evidence. And so the burden of proof should be on the party making the extraordinary claims. And if there's a party who's going to show up and say, you know, AI models are like nukes and California should start imposing downstream liability on open source developers for open sourcing the weights, that's a pretty high claim to make. And so you should have like exceptional proof if you want to change the status quo within the status quo is you do not hold scientists liable for downstream uses of their technology. That's absurd. We need to shut down the entire innovation ecosystem and start throwing literally like researchers in jail. We don't want that. We want them to be trying to push the frontier forward. And I just don't think that the tall claims were not being followed up by tall proof. When we're talking about open source, are we all talking about the same thing? Meaning are there degrees of open source or is it kind of just like a binary? Open weights, I think, was the primary contention, which is that if somebody put out an open the weights of a model and a bad guy took those weights, fine tuned it, did something really terrible. Two years later, the SB 1047 regime proposed that the original developer of the weights and that they put out basically as free information should be held liable, which was absurd. Right. Right. So I think a way to make sure we're very clear because like, you know, people jump on top of these things. Right. What he's saying is correct. So basically, if the weights were over a certain size and there was a mass casualty event, I think and the catastrophic harm was the word used, but there were no real mass casualty. There are so many versions. Actually, I don't know which version you're talking about. Yes. But I remember we actually looked it up. The legal definition was three or more people were killed or the medical system was overwhelmed, which there was actually precedence of this, including like a car crash. Right. Right. And there was actually precedence of this happening in a rural area, which basically doesn't have any sort of capacity. And so, you know, basically it would move the conversation to the courts and outside of policy, which is, again, historically, we've taken a policy position on these things which follows precedence that we understand, you know, to make sure that we don't introduce externalities like, for example, allowing, you know, China to race ahead with open source, which is, you know, which has happened. And the key thing is you by moving it to the courts, even if you don't, you could you one could argue, oh Anj, but like, sure, it's moving to the courts. That means it's open for debate. It's not clear that open weights are going to be regulated with liability. The point is that that creates a chilling effect. The chilling effect is the idea that when our best talent is considered. I could be sued. Like, I'm like, you know, I'm a random kid in Arkansas developing something like I don't want to be in a world where it can be resolved in the cars, right? I can't even afford, you know, whatever. And in a situation where you have an entire nation state backed entity like China, actually doing the opposite of a chilling effect, right, encouraging a race to the frontier. Why on earth would we want, you know, that there's this meme of a guy on a bike and he picks up a stick and puts it into his front wheel and topples forward. That's the effect of it. That that is what chilling effect is, right? At a time when your your primary adversaries is racing. So let's trace how the conversation has changed because we don't see Vinod tweeting about open source anymore. Obviously, it's changed your tune, especially right now. What is it really just deep seek? Is that or how do you trace kind of how how the sentiment shifted on open source? Let's let's go through a few theories. I'm not really sure what happened. I almost felt like it was almost culturally in vogue to be a thought leader on the negative externalities of tech. And it kind of started with both Trump, but it was picked up by Elon. It was picked up by Muscovites, I mean, a bunch of like these intellectuals that like we all respect and still do. I mean, they're just really the titans of our industry in our era. They were asking these very interesting intellectual questions around, like, do we live in a simulation? What happens if I can recursively self-improve? And then actually, you know, that created a whole kind of cultures and online social discourse around this stuff. And so I think to no small part, that became a bit of a runaway train and it's just catnip to policymakers. Yeah. And so I think part of it is like people didn't really realize that this has become so real because, of course, GPT-2 comes out and then three comes out and like all this stuff's amazing and somehow it got conflated. So I think part of it is just a path dependency on on where we came from, which is kind of the legacy of both Trump. I think that was part of it. I think the ungenerous approach would be would be that there was a lot of discourse is awesome, but a lot of the people pushing the discourse were first order thinkers. They weren't doing the math on, wait, wait a minute. If policymakers who have no background in Frontier AI, which, by the way, nobody does because this space is only three, four years old, start to take discourse as canon, which is a big difference. Then what happens? What are the second and third order effects? And the second and third order effects are that you start making laws that are really hard to undo and start mistaking interesting thought experiments as the basis for policy. And once that happens, those of us who look, law is basically code. Code is hard to refactor. Law is like impossible to refactor. And so I think the second and third order effects was that were of a lot of well-intentioned folks, for example, in the existential risk community saying, look, if you're intellectually honest about the rate of progress of AI, it's not crazy to say that there are some existential risks on the technology. It's not zero. Sure. Yes, that is true. But then to then say that that threshold is high enough to start introducing sweeping changes in regulation to the way we create technology. That leap, I don't think a lot of the early proponents of that technology realized they would do that. In fact, I think Jack Clark, who runs Policy Philanthropic, literally tweeted like towards the end of the SB1047 saga, he was like, I guess we didn't realize the impact of how far this could have gone. And I think to those of us who had interacted with DC before and regulation before, like the second and third order effects were much more discernible, legible. And then I think what DeepSeek did was just made it super legible to everybody else. So I think they were already like, I think DeepSeek was the catalyst. But it wasn't like there was a step. It didn't change the reality that the second and third order effects of policymakers confusing sort of like discourse for fact were always going to be terrible. I just think it brought to light something a lot of us were already saying, which is when we're in a race with adversaries, and that should be the calculus we should be working backwards from. Yeah. There was always this prevailing view, which has turned out to be so wrong from really well-intentioned people, which was like, it's going to be regulated anyways, if it looks like we're self-policing, we can dictate, you know, how that happens, right? And unfortunately, that just turned out not to be true, because, you know, whatever self-policing we seem to be doing scared the shit out of people. And then of course, I would say very opportunistic elements in tech decided to use that for whatever agenda that they had. And so it kind of got away from us. And so Mark had this sort of the Baptist bootlegger. Yes. I was just going to say exactly. True believers and then sort of people who use the sort of that thinking for to support their own ends. And it seems like that's changed, even as on the company. But the reality is, I think it was driven, I think the majority of people are neither. The majority of people are pragmatists that are not trying to take advantage of the system that think, well, maybe if we have this discourse, it's an honest discourse, and then we'll self-police. And then I just feel like the silent majority was not part of the discussion. Maybe the biggest change now is like, those people are there, like the founders are there, academia is there, VCs are there. Now, the people that are not either Baptists or bootleggers are driving the discussion, which is independent of the action plan itself. I feel much more in a better position now. Like, for example, there's still a bunch of stupid regulation that's popping up, but I'm not calling Anj at night and saying, we have to do something now, because I feel like, OK, there's actually representation that's sensible. At the time, there was not. And I think to move to the action plan, I think this is a great, like, if you read the first page, right, what a marked shift, the fact that the co-authors include technologists. And I think that was the core problem, is DC is a system, like a self-contained system, and the Valley is a self-contained system. And I think a lot of the people here were assuming best intentions over here and vice versa. And what happened is a few bad actors essentially used that arbitrage opportunity to represent Silicon Valley's views incorrectly in DC. And when we saw some of the legislation, we had policymakers calling us up and saying, wait, you guys aren't happy with 1047? But the guys, the other tech people were calling us and saying, you'd love more of this kind of regulation. We said, what other tech people? And it turns out, we are not one homogenous group. Little tech is extraordinarily different from big tech, which is extraordinarily different from the academic communities. And I think one of the things we had to contend with was, like, we used to be one shared culture. And then when tech grew, we actually, there are some major differences, in the Valley at least, between parties. We're not one tech ecosystem anymore. We have different interests. And DC hadn't updated that. And I think what's amazing about the action plan is it's written by people who have bridged both, with enough representation across, like, the four or five different subcultures within tech who have different interests. I think that's new. Yeah. Going back to open source, why don't you talk a little bit about just sort of the, how different companies, help us make sense of how different companies have thought about it, or from a sort of business strategy perspective, you know, maybe we saw Meta with maybe the first big open source push, you know, open AI has sort of evolved their tune. I've seen even Anthropic seems to be evolving their dialogue a little bit. How should we think about open sources as a business strategy in terms of what's changed here and why? Oh, look, I don't think this is, this part is actually, is playing out beautifully along the same trend lines of all previous computing infrastructure, databases, analytics, operating systems, like Linux. The way it works is the closed source pioneers the frontier of capabilities. It introduces new use cases, and then the enterprises never know how to consume that technology. And when they do figure out eventually that they want cheaper, faster, more control, they need somebody like a red hat to then introduce them and provide solutions and services and packaging and forward deployed engineering and all of that around it. And which is why the arc generally in enterprise infrastructure has been closed source wins, applications, and open source tends to do really well in infrastructure, especially in large government customers, regulated industries, where there's a bunch of security requirements, things need to run on prem, the customer needs total control over it. Broadly, you could call that the sovereign AI market right now, lots of governments and lots of legacy industries are going, wait, this open source thing is really critical to us. So I think whereas two, three years ago, it was open source was viewed as like this, like largely philosophical endeavor, which it is, open source has always been political and philosophical by definition. But now there's an extraordinary business case for it, which is why I think you're seeing a lot of startups and companies also changing their posture because they're going, wait a minute, some of the largest customers in the world, enterprise customers happen to be governments and happen to be legacy industries and fortune 50 companies, and they want stuff on prem. And that's when you go adopt open source. I say, I think there's been a business shift as well. I don't know if you do. Yeah, this is great. So I totally agree. I do think it's interesting to have a conversation where it's the same and where it's different. Like everything Ansh said is exactly right, which is we have a very long history with open source and it's a very useful tool for businesses, but also for research and academia, et cetera. But let's just talk about businesses and startups, right? It's a great way to get a distribution advantage. It's a great way to enter a market where you're not an incumbent and you're a startup. So it's just kind of one of the tools for building in software that's been used and open source has been used in a very similar way, right? I mean, you can use it for recruiting, you can use it for brand, you can use it to get distribution and we see all of that. There's something that's unique about AI that software doesn't have and like we're seeing very viable business models come out of it that don't have the limitations of traditional software. And this is for two reasons. One of them is like open weights is not the ability to produce the weights, but open software is the ability to produce the software. Like if you give me open software, I can compile it, I can modify it, whatever, but giving open weights, you don't have that. You don't have the data pipeline when you're talking about open weights. So you don't actually enable your competitors in the same way open software enables it. So that's one. The second one is this is very nice business model that's kind of a piece dividend to the rest of the industry, which is you open weights to your smaller models that anybody can use, but the larger model you keep internally, which is actually also more difficult to operationalize for inference, right? I mean, there's kind of good reasons to do this. And then you charge for the largest model and then, you know, the smaller open models you use for band or distribution or whatever. And so I feel like it's actually almost an evolved from a business strategy and an industry perspective version of open source for these reasons. I think it's the AI flavor of open core, which was historically a theoretically, was supposed to be a theoretically sort of sustainable model for open source software development, which was really hard to implement because of the reasons Martine said, where once you gave away the code, it was really hard for you to protect your IP. But with weights, you can contribute something to the research community. You can give developers control. You can allow the world to red team it and make it more secure while you're still able to actually, because of the way distillation works and some of the ways like post-training works, you can still actually hold on to some of the core IP, which then allows you to build a viable, sustainable business. And that is unique about open open. But also you have the data pipelines, you have the data. Like I mean, nobody else could just give you the weights doesn't mean you can recreate the model. You can distill it to a subset model. There's a bunch of stuff you can do, but not necessarily recreate it. And so I, listen, having been kind of a student of open source business models for 20 years and have watching, you know, it, it shaped the way that the, the industry has adopted and built software. I actually think that the AI one is more beneficial to the companies doing it for sure. But as a result of that, we're going to continue to see a lot of it. And so I think we should just kind of assume that open source is part of it and every country is going to do it. And one of the best things about this current AI action plan is it acknowledges that and it wants to incent the United States to be the leader in it, which is such a dramatic shift from where we were this time last year. Yeah. There's sort of an ecosystem mindset that people who, if you've worked in any kind of developer business, which Marti and I unfortunately have spent way too long doing, working on dev infrastructure and dev tools, but you sort of internalize this idea that when, if you, it's often, you have to often sort of trade off short-term revenue for long-term ecosystem value. Right. And I think what this, the action plan shows is that yes, in the short term, it may seem like we're giving away IP to the rest of the world by open sourcing weights and showing the rest of the world how to create reasoning models and all of this stuff. But in the longterm, if every other major nation is running their entire AI ecosystem on the back of American chips and American models and American post-training pipelines and American RL techniques, then that ecosystem win is orders of magnitude more valuable than any short-term sort of give of IP, which anyway, as we saw with DeepSeek, that marginal head starter is minimal. Okay. So just to close the loop on open source, over the next several years, how do you predict open source and closed source will intersect? Like what will the industry look like? Well, I think these are two different markets. Yeah. I mean, literally the requirements of the customers are completely different, right? So if you're a developer, you're building an application and you happen to need the latest and greatest frontier capabilities today, you have a different set of requirements than if you're a nation state deploying like a chat companion for your entire employee base of like 7,000 government employees and you need, and the product requirements, the shape of how you provide those, do you deploy them, the infra, the service, the support, and then the revenue models are completely different. And so often I think people don't realize that closed source and open source are not just differences in technology, but completely different markets altogether. They serve different types of customers. And so, and I think if you believe AI is this sort of explosive new platform shift, then there'll be winners in both. I do think what we need to contend with is that it seems like it's getting harder and harder to be a category leader if you don't enter fast. Like the speed at which a new startup is able to enter the open source or the closed source market and create a lead is absurd, right? We both have the chance to work with founders who are, I mean, literally 20 something year olds out of college, two years out of college building revenue run rate businesses in the tens to hundreds of millions of dollars serving both of these markets expanding like this. And so I think the biggest mistake is to confuse these two markets as one and to do the classic like, oh, let's wait to see how they evolve because the pace at which a new entrant is able to actually create a lead in the category is quite stunning. Let's go into the action plan. Right. What are our biggest reflections from it? Where are we most excited? If you look at the quote that they start with, I wanted to read it out because I thought it was pretty poignant. It was, today, a new frontier of scientific discovery lies before us. And I thought that first opening line was fantastic out of all the things they could have said. You know, they could have said we're in a nuclear, we're in an arms race, which sure, the title says winning the race. But if you actually start reading the document, the first sentence is a quote from the president that says, today, a new frontier of scientific discovery lies before us. I love that they led with something inspirational. Because ultimately, the technology has to confer some benefits on humanity. And I personally, I just love the fact that we are just starting to explore what these frontier models mean for scientific discovery in physics, in chemistry, in material science. And we need to inspire the next generation to want to go into those areas because it's hard. It's really hard to do AI in the physical world. You have to literally hook up wet labs and start doing experiments in an entirely new way. And you need people who are excited, not only about wanting to do machine learning work, but also the hard work of being lab technicians and running experiments and literally pipetting new materials and chemistry. And that, I think, was missing in a lot of the discourse under the previous administration. So you can sometimes judge a book by its cover. And I think this is a strong start. And now I think we should actually dive into some of the bullets. OK, so the other one that I thought was a huge omission is there's basically no real mention of academia, investing in academia. There's some oblique references to it, but it's just been such a mainstay of innovation in computer science of the last 40 years, not having a major part of it. I think it's a shame. And I understand that right now there's kind of a standoff between higher ed and the administration. I get it. And I actually think that both sides actually have fairly reasonable points. But to have a major tech initiative without including academia just feels like we're, you know, what is it, fighting a battle with a hand tied behind our back, like some aphorism. This is a good problem to have, which is that I think it's extremely ambitious. It's a little bit light on execution details, right, which is what happens next. So a good example of that is I think I do think directionally, it was great that they said we need, let's read this bullet point on build an AI evaluations ecosystem. I love that because it acknowledges that, hey, before we start actually passing grant proclamations of what these models are risky or whether these models are dangerous or not, let's first even agree on how to measure the risk in these models before jumping the gun. That part, I think, in addition to the open source bullet was probably, I thought, the most sophisticated thinking I've seen in any policy document. And look, the reality is America leads the way. And so every other, you know, within 24 hours of this dropping, Marti and I were getting texts and messages from folks in many other governments around the world going, what do you guys think? And it was not hard for me to endorse it and tell them, like, look at it as a reference document because there are things here that arguably are more sophisticated than policy experts even in Silicon Valley would recommend. Because building an AI evaluations ecosystem is not easy. And I think they had a pretty thoughtful proposal on the fact that that's important. Now, the question is how. And I think that's what we have to help DC with the hard work of like implementing this stuff. But the vibe shift going from let's not jump the gun on saying these models are dangerous. Let's first talk about building a scientific grounded framework on how to assess the risk in these models to me was not at all a given. And I was really excited about that. Yeah. There has been a lot of focus in the last few years by several companies, but also by the broader industry around this idea of alignment. Have we made any progress on alignment? What is your sort of perspective of what are they trying to do? Is that a feasible goal? Help us understand what they're trying to solve for. So at an almost tautological level, alignment's an obvious thing you'd want to do. I have a purpose. I want to align the AI to this purpose. And it turns out these models are problematic, generally unruly, chaotic, whatever adjective you want to use. And so understanding how to better align them to any sort of stated goal is very obviously a good thing. And so I think we'd all agree that alignment to whatever the goal is to make it more effective that goal and do that thing is good, especially given these models who tend to have a mind of their own. The subtext that certainly I bristle to is that the people doing the alignment are somehow protecting the rest of us from whatever they think their ideal is as far as dangers to me or thoughts I shouldn't have or information I shouldn't be exposed to. Which is why I think we need to be, even when we come up with policy, we need to be very careful not to impose a different set of ideological rules on top of these. I just think alignment is something we should all understand. Aligning them to me is kind of where I take issue from any sort of kind of top down mandate. I agree. And I think there's a quote from a researcher, which I think is very accurate, which is you've got to think about these AI systems as almost biological systems that are grown, not coded up. Right. Because sure, they express a software, but in many ways, when you're training a model, you are actually growing in this environment of a bunch of prior history and training data, et cetera. And often empirically, you actually don't know what the capabilities of the model are until it's actually done training. So I think that's a useful analogy. Where I think that falls down is when people go, oh, well, if we can't align it because we actually don't know, it's a biological mechanism, until it's grown up, you don't know what its risks are and so on, then we can't deploy these AI models in mission critical places until we've solved, let's say, the black box problem, the mechanistic interpretability problem, which is, can you trace deterministically why a model did something? We've made a lot of advances as a space in the last few years, but it still remains a research problem. But that doesn't mean just because you don't understand the true mechanism of the system doesn't mean you don't unlock its useful value. If you look at most general purpose technologies in history, electricity, nuclear fusion, like there are many examples of technologies where we knew there were complex systems and we didn't truly understand at an atomistic level or mechanistic level how they work, but we still use them. And we don't understand how the internet works. I mean, like there's a whole research of network measurements trying to find out what the heck the internet was going to do. Is it going to have congestion, collapse? I mean, like, you know, any complex system has states that you just don't understand. Now, let's not say these models more so than many, and the implications are very real, but like we know how to deal with ambiguity. We don't even know how our own brains work. No, we think. Consciousness. Yeah. But we don't stop working with other human beings. Fortunately, we're stuck with them, so we have no option on that one. I mean, I think to extend that analogy, what do you do? You're like, okay, I don't know how a brain works. It's got a bunch of risks. This person may be crazy, but I still want to unlock all the beautiful benefits of the big, beautiful brains that humans have. And so you develop education. You send kids to school and you teach them values, and then you send them off to college and then they get to learn something specific, and then you get to test them in the real world environment. They get a resume and they get work experience and they get to prove that they actually are within a risk-based framework, manageable and so on. And that as a society has unlocked human capital, right? Arguably the greatest technology we've had in 500 years of modern industrial innovation. So I think what I hate about the alignment discourse is it sometimes confuses the fact that we don't understand the system for the fact that then we can't use it. And I think, I don't think we've, like for a long time, I think mechanistic interpretability, which is kind of like some folks would say is the holy grail, is like being able to reverse engineer why a model does something is still a research problem, but that doesn't mean we haven't made progress on how to use unaligned models or to improve alignment to a point where they're useful in massive ways, like software engineering. And I think what the smartest might say is, it's not that, it's really just what's the rush. Maybe let's focus on integrating all the capabilities we already have before pushing the frontier to which then it ends, well, but the arms raised, et cetera. There's a risk of slowing down too that maybe isn't fully appreciated. Until we've solved cancer, every month that we're not rushing to the frontier of accelerating biological discovery or scientific progress is a month that millions of people are suffering from disease that we could be solving with AI. We don't talk about the opportunity cost of slowing down the frontier. Yeah. I mean, this is the thing with all of these, like there's always this kind of reverse question on innovation and they say, well, okay, it's like the Bostrom urn experiment. You know, his whole urn hypothesis, like there's an urn of innovation and you pull out balls. One of them is a black ball that destroys everything, right? So eventually you'll draw that ball, so why would you ever do innovation? Like that is the thought experiment. And the answer is so simple, which is it just turns out that it's much more dangerous not to pull out balls than pull out balls. Like that's always the answer. So like when people ask PDoom, so what is the PDoom? The answer is not like 0.1 or 0 or 100. The answer is the PDoom without AI is actually quite a bit greater than PDoom with AI. And the what's the rush? The answer is the same thing, which is clearly if you ignore, exactly, if you ignore the benefits of technology, then you would say, if it's all negative, no rush at all, right? But the reality is, is the benefits are, they're so dramatic and they're so obviously dramatic now. Thank God we've got a year's worth of data on this stuff. Like they're clearly economically beneficial, they're clearly beneficial expanding a number areas of like core science that the rush is getting to the next set of solutions, you know, as opposed to being afraid of, you know, a set of problems that we still can't clearly articulate. But as soon as we do understand marginal risk and we do have these, we absolutely should address those directly, which again, the action plan does a great job of penciling this out. I mean, it does want to explore implications and jobs, implications on defense, implications on, you know, alignment, like, and that's exactly where we should be in the exploration phase. Do we have a definition of marginal risk that or a perspective of how to think about that idea? Well, let's just be clear what we mean by marginal risk, which is computer science or computer systems are risky, network systems are risky, stochastic systems are risky. We've been, we've got decades of, you know, ways of thinking about measuring, regulating, changing common behavior based on this type of risk. And so the question is, can you take all of that apparatus that's been hard won and apply it to AI? If so, like, A, we know it's effective because we've used it before and we've got a lot of experience with it and B, it's ready to be done. Or is there a different type of risk that's not endemic on those systems? In which case we'll have to come up with something that new, which is, you go down that exploration, maybe it works, maybe it doesn't work, et cetera, right? So that like, that's what marginal risk is. And I just think that the problem is, is if you don't, if you don't know what it is, how are you going to define a solution? I think that's right. I mean, philosophically, the idea is if you're going to say we need new solutions, then you need to articulate why the problem is new and why our solutions that work really great are not, are no longer sufficient. Right. And I think it's, it's almost obvious when you state it, but this was the state of the world a year ago that we were having to like look around the room and say, can I raise my hand? But why are we introducing net new liabilities and new laws that we've never had to do before? If you can't articulate why there are no new problems to solve. If it ain't broken, why are you trying to fix it? And so marginal risk is, I think, a slightly just more technical way to say, we have the tools to manage risk. We don't need new ones. And if you think we need new ones, then hey, just take a minute to articulate to us why. Is there anything else you wanted to make sure we got to? Otherwise let's, I think this is great. Time to put the action plan into action. Excellent. Martin, Ansh, thanks so much for coming to the podcast. Thank you. Thanks for having us. Thanks for listening to the A16Z podcast. If you enjoyed the episode, let us know by leaving a review at ratethispodcast.com slash A16Z. We've got more great conversations coming your way. See you next time.


---

## 2025-08-14

### H20s to China + 15% with Chris Miller and Lennart Heim
**Publication Date:** 2025-08-14T19:21:51
**Episode ID:** 5079

**Full Transcript:**
emergency podcast we're bringing back Leonard Haim of RAND and Chris Miller you guys know who Chris Miller is to talk the new h20 drama we went from banning it in April to now selling it with a 15 percent export fee all right Leonard why don't you start our narratives what is the h20 why should you care about it and what were the first few months of the Trump administration doing when it came to this chip the h20 is the chip which NVIDIA designed as a response to export controls in 2023 right it's a typical game you draw some lines and then new chips get created right below the lines and the h20 is such an example but it did a neat trick it maxed out the specifications which are not controlled memory bandwidth so putting on the best high bandwidth memory world the world currently has on this chip and created a export control compliant chip which I think was introduced at beginning of 2024 so a couple of months after the update and we will sort over 2024 lots of interest in this chip and when then the Trump administration started in January they well we can say the Biden administration didn't get to it I think it would definitely weigh out this problem many of their officials came out many of them even favor but they just never got to banning to it because again many stakeholders many different opinions and also just kind of running out of time but Trump then banned this chip as we saw reported in April 2025 not by the normal means how you do it not by a passing regulation via using a cool tool called is informed letters because they're pretty fast and you can just send a letter to the companies which produce these chips and tell them like hey you can't sell these chips anymore because we expect us an export control violation going on and we actually think this chip is too good so that's where we started so the chip was banned for my personal point of view a big success I think this chip should not be sold we need to reduce our thresholds this is just simply too good of a chip and well then then this was the less later status and I think in the last few months last few weeks we saw some flip-flopping back and forth and every day reveals more information and I don't know why we talk probably more things will come out over time all right so this was President Trump on Monday two questions one about China one about Russia if I could on China if your administration agreed to send the most advanced or advanced Nvidia and AMD obsolete no obsolete well and in 15% of probably in the 20s no no that's this is an old chip that China already has and I deal with Jensen who is a great guy and Nvidia the chip that we're talking about the h20 it's it's an old chip China already has it in a different form different name but they have it or they have a combination of two will make up for it and even then some now Jensen also has Jensen's a very brilliant guy and Jensen also has a new chip the blackwell do you know what the black well is the black well is super duper advanced I wouldn't make a deal with that although it's possible I'd make a deal a somewhat enhanced in a negative way blackwell in other words take 30% to 50% off of it but that's the latest and the greatest in the world nobody has it they won't have it for five years but the h20 is obsolete you know it's one of those things but it still has a market so I said listen I want 20% if I'm going to prove this for you for the country for our country for the u.s. I don't want it myself you know every time I say like like 747 I want I want yeah for the Air Force that's so I just wanted so when I say I want 20 I want for the country I only care about the country I don't care about myself and he said would you make it 15 so we negotiate a little deal so he's selling a essentially old chip that Huawei has a similar chip a chip that does the same thing and I said good if I'm going to give it to you because they have a you know they have a stopper what we call a stopper not allowed to do it restrict is really known as a restrictive covenant and I said if I'm going to do that I want you to pay us as a country something because I'm giving you a release I release them only from the a th20 now on the black well I think he's coming to see me again about that but that will be a unenhanced version of the big one like I don't know if you know we will sometimes sell fighter jets to a country and we'll give them 20% less than we have do you know what I mean it's just yeah it's crazy to see you like this discussion also to the level of sophistication you're right knowing age 20s knowing the black was my name knowing what Huawei it's clearly a big topic now we're this this this whole exponent of things in the spotlight so I think it's a good moment to kind of take a step back and look at the arguments in favor and against selling China AI chips so against selling you have broadly the argument that selling AI chips helps upgrade the Chinese AI ecosystem that's going to compete with America's broadly and that there are specific applications of the chips that we would be selling to China which we would be very uncomfortable with like military ones or intelligence ones or sort of broad human right by human rights violations that you wouldn't want sort of America and technology to be helping to further and then the arguments in favor of selling we have this idea that actually selling Nvidia chips would retard domestic chip development make it harder for SMIC and Huawei and whoever else wants to try to build in a domestic AI chip to find a marketplace and this idea that selling chips into China would maintain American Chinese dependency on the US stack so it keeps Chinese developers using CUDA building infrastructure around US technology and you know some sort of like broad soft power agenda setting advantages to be determined that China using Nvidia hardware will give to the US going forward. So maybe we should run through those maybe we should run through those systematically I guess you know let's start with the biggest one which is you shouldn't sell these chips to China because upgrading the Chinese AI ecosystem is like a strategic threat to the US and I think that's a thing maybe we'll throw this one to Chris I mean this is a this is like a this is like a grand strategic question almost of like how much of China's rise is okay and how much of it isn't because you know the military intelligence human rights applications are almost secondary to like just how scary you see a richer more flourishing more powerful China to be right? Yeah and I would even segment out the sort of richer and more flourishing side and just talk about technological capabilities they're obviously interlinked but I don't think US strategy has been to try to make China poorer or less flourishing in general I think the question is just who's going to lead in an AI the trend over the last five years and really the last 50 years has been that if you want advanced AI you need lots of advanced computing and there's a small number of companies who produce the chips in question and so if you think that advanced technology has mattered in the past in Tio's competition which I think is pretty hard to argue with it's probably gonna matter in the future and therefore who wins in AI you know it's a little bit reductive to ask but I think it also it matters and just like we would be a less happy if we were all using Huawei phones and relying on Alibaba cloud because I think there'd be pretty significant political ramifications that were downstream of that so too if we find ourselves in a future where either the US or third countries are relying on Chinese AI providers whether for models or for applications or for AI cloud that implies less political influence for the US a weaker US and a stronger China so that's the stakes and I think to some degree both sides of this argument agree on that basic framing question is how best do you get there you know one argument is that you restrict compute access and thereby hobble the growth of Chinese AI firms a second argument is that you try to you know as Secretary Lutnick has said get China addicted to the AI stack and the question to ask is you know how addicted are they willing to become and how addicted could you actually make them and can you leverage that addiction in the future or or not and I think these are where the the empirical questions are are really focused and I think kind of one more on the in favor of selling argument this idea that keeping China dependent on you know TSMC fab shifts actually lowers the risk of a Taiwan war which I have some questions about but this is something that Ben Thompson has been pushing which I think has also percolated into the into the administration and Congress like my mom threw me that one the other day anyways what do you think what do you make out of it Jordan I'm like I'm like for me it's like it doesn't seem to be the main calculus behind it like I I buy it gets on the margin I think maybe on the margin a little bit I think there's two levels to the question first at the political calculus to go to war or not to go to war it seems very this is like this would be an extremely kind of weighty decision where you know the fates of nations would be at stake to do a serious blockade or to you know do some strike or some way of or some actual you know d-day style invasion and you know whether or not the chips are there China's sort of like you know gaining relatively or lose relative losing relatively in AI hardware just strikes me as like the 12th thing that you would be thinking about if you were a Chinese premier I mean domestic political developments political developments in Beijing political developments in Taipei just how willing the u.s. is seeming to fight for Taiwan how excited Japan is to let the u.s. fight from right from its territory all of those strike me as much more germane decisions and there's a bit of sort of like technological myopia of tech analysts thinking that like oh the chips are the one thing that's like this silicon shield stopping it it's like no like we're I'm sorry I really as as as cool and important and you know over a 50-year period potentially like world shaking as you know advanced semiconductors and artificial intelligence maybe you know if you are a head of state this isn't and making the biggest decision of your life I don't think it's really gonna come down to like oh well Huawei tells me they can only make 750,000 chips in 2028 so then it's not gonna work out but I do think sort of one level down from that there is this very open question which we debated on Sunday's edition of second breakfast about to what extent the that the chips and the technology that are they're going to be enabling ends up sort of reshaping the military balance of power and I think that is still very much an open question that smart people can disagree on on whether or not you know whatever you can do with you know putting chips in your autonomous drone so they can like target without being interfered with or what have you you can imagine a lot of a lot of different crazy futures where where AI really matters and by the way like it could actually work in the other direction of lowering the risk of Taiwan war if America has a big lead when it comes to semiconductors because then a Chinese or a leader in Beijing would look at the military balance of power a balance of power and the advantage that the US and Taiwanese forces get from being more you know AI-ified that they see oh you know there's no chance of us winning why even why even try to play this game in the first place. I think the other key facet here is that if you look at sales of advanced chips from Taiwan and its ecosystem to China most of them are not AI chips it's mostly smartphone chips and PC processors and and AI chips are a portion but a small portion. I think it also gets back to the question I know you've raised a lot of shows Jordan which is how AGI-pilled is Xi Jinping and the answer is you know doesn't seem that AGI-pilled. Best evidence for which is that you know SMIC in its 7-9 year production is still producing a whole lot of smartphone chips which you would not do if you thought we were in a race for for AGI which will define the future so both of those facets again point against the silicon shield as it relates to AI chips being absolutely central here. And also just to clarify they're not allowed to produce AI chips at TSMC they can produce everything else there. Huawei not because an entity list you know they did some bad stuff but almost every other Chinese company can just go to TSMC and produce chips there right so there's like significant flow of chips from Taiwan as of as we're speaking right now to China right which is not a ideally not AI chips you know we we had some hiccups in the past where it was also AI chips right. So I think a key question Leonard is how obsolete is the H20 relative to a what what Blackwell's can do but probably more importantly be what Huawei can do. You want to walk us through the numbers? What I would just say I don't think describing the H20 as an obsolete chip is is fair right. Chips have many specifications right and let me try to break it down two simple ones we should care about the computational power how many flops it has how many operations per number per second it can crunch but then also memory bandwidth this means basically you need to read and write memory and the memory capacity and the bandwidth how fast you can read and write this memory is key. And one of the key inventions we've seen over the last few years which actually AMD did first is so-called high bandwidth memory which is a pretty complex technology. We've got three companies in the world doing it right now. SK hynix, Samsung and Micron building this HBM and the H20 is really bad on the flops 7x worse than H100 even more worse 14x worse than like the upcoming chips in the B100s and more right so it's definitely no competitive chip here. But on the memory bandwidth side which is again key for deploying chips it's pretty good it's even better than H100 because the H100 uses five units of HBM whereas this one has six units of HBM so it gets a mind like boggling four terabytes per second of high bandwidth memory and no Chinese chip has such good high bandwidth memory and more importantly even if they have right now like 910C which has some HBM I think it sits at 3.2 terabytes per second they're not allowed to buy it anymore it's banned since December 2024 right so right now China would be struggling to first of all getting their hands on this HBM and they're trying to produce it domestically but as well this will take a bit and even if they produce it domestically it would initially be worse so I don't I don't think the H20 is an obsolete chip it's a pretty pretty competitive chip I think it's definitely fair to say it's a worse chip than many others that's fair to say but again if you look at this other dimension this dimension of deployment it's pretty good it's really really good I think that is it one of the key actions of debate you know some people say the goal is to stop China from training high-end and therefore you focus on the flops if your goal is to constrain inference you focus more on memory bandwidth walk us through the way these different chips are used yeah I think that's a fair debate to we should be having here right like we should think about with Xpoken what do we want them to achieve and I think right now it's fair to say the H20 is not an amazing chip for training AI systems there are some things which numbers don't always capture right like you still build on top of the NVIDIA software stack if your company which used NVIDIA before there's like a little bit of a pain to switch there's a bunch of problems of Huawei chips which you don't really see in the specifications right to overheat you need more of them the software stack isn't great yet do you can even get enough right all of these things just mean that H20 is not a great training chip but beyond the numbers it's still you're stuck on a software ecosystem so on the training goal I think it's still being achieved here where the debate begins is what do we think about deployment and what at least I've learned over time here and is if you want to be really precise right if your goal is to only stop them from training but everything else is below it or you only stop them from training big systems it's really hard to be precise on all of this and then AI is ever changing and I think the most biggest thing we've seen over last year is like this this rise of test time compute of AI models thinking right how do they think will they produce tokens and that's what the H20 is like really amazing at right so one could say the usability and importance of the H20 only went up ever since because we got models which do more thinking generating more tokens and also generating tokens to then train the next generation of AI systems right and I think these are the arguments which people would say like well actually this is a pretty good chip right for producing these new things which are like more important in AI development lifecycle. So the other argument that the president made is that Huawei already makes these chips which is you know true to an extent but walk us through the numbers there as as you see them I know that there's questions both about the quality of Huawei's chips as well as the numbers that can be produced I know Secretary Lutnick said they can produce 200,000 a year and I suppose that's right how does that compare with with what we're going to see with H20s? The key dimensions here are just quality and quantity and I think many always talk about the quality argument here I personally think the quantity argument is way more important you already mentioned the number from I think Lutnick said and Kessler also testified that 200,000 ASIN chips being produced in 2035. How does this compare to the US? I think we're churning out around 10 million chips this year so significantly more this means if we're selling and I think there have been projections about Nvidia selling a million H20s we sell them five times more what they can produce right and I think this is where the debate starts the quantity argument is like really key here if you would only sell them a couple of thousands or like 200,000 something that's a vastly different debate and selling in a million or potentially even more and just a sign that China wants to buy them speaks to like their problems of producing domestic chips right so on the quantity side China is simply not there yet they're getting better and they're producing more chips the minute we speak that's the case but there are many difficulties even to produce more chips have to have high bandwidth memory how good is their smuggling operation to get this memory how good is their packaging yield all of these things just add up that you eventually just really can't produce competitive chips then they at the end they get chips out of it if you compare the ASIN 910C to Nvidia's best chip right now which is being sold to B200 it's way worse right it's way worse on the high bandwidth memory part and it's also way worse on the computed performance and it's also worse than H20 which is selling at least on the memory part which we're seeing here and the point is if you're selling the H20 think what many missed there's a chip at least there were rumors around it and I think there were pretty good rumors there's a chip called the H20e what does it do it doesn't use HBM3 it uses HBM3e so I previously said it has four terabytes per second if you use HBM3e you can probably go up to five terabytes per second or even more right and which indications do we have that this chip is not getting sold right the flops are still being kept but the memory just continues going higher and higher and higher and I think that's another thing to be tracking here and as long as we don't have updated regulations for it we just don't know where where the line is going to be drawn here in terms of quality of memory bandwidth but also most importantly in terms of quantity so if I could ask for one thing please reduce the quantity I think that's the key thing we should pay attention to here. I think you know one of Nvidia's lines that Jensen has been saying a lot is like they used to have 95% market share before the restrictions and now it's down to 50% first off they've never actually given numbers for that but second my guess is that they were the only people making you know accelerators that people wanted so even if it did go down to 50% it's not like it was the same pie like the pie went down such that that 5% that it used to be now turns into 50% of the whole pie so the the idea that sort of Huawei like that number does not tell you that Huawei necessarily has the capacity in order to fill it up and as and as Leonard said like the Jensen cares about this because lots of Chinese companies are willing to spend his projection is what like 15 billion dollars a year in sales and to think that like I mean you know Huawei and Baidu and Tencent they are not dumb like they are going to spend billions and billions of dollars of capex by the way this capex number you know seems small if you're talking about Google and meta but it's actually pretty large relative to the sort of total capex that you're seeing from the Chinese hyperscalers so like they're doing this because they think it is useful and important and relevant to their sort of you know AI ambitions going forward not to like do Jensen a favor or anything. Can we talk about what we know in terms of who in China will be the large-scale buyers of these ships Jordan you mentioned Tencent, Alibaba there's AI firms like DeepSeek there's ByteDance a huge player in China's ecosystem I don't know Leonard if you have a sense of numbers of any of those are public or at least talk about kind of who are who are the buyers these ships inside of China. I don't think they have public reporting of exactly there's definitely been some reporting that big hyperscalers the big cloud companies right Tencent, ByteDance and others are definitely interested in this. I'm not sure interested in ByteDance because they're building tons of clusters in Malaysia which by the way can buy whatever chips they want to buy there and just continue building. So I think just the normal hyperscalers go there they will continue buying these kinds of chips but they all hatch right they all also get ASIN chips they're not stupid right we just see with the policy flip-flopping that they don't know when they're gonna get cut off right so they're all just hatching with like Huawei's and chips while they're getting better. There's something we would just subsidize the transition while we do this right and that's that's like the thing which I'm worried about here it's just it's just the case that Huawei will get better they will produce better chips I think the ships will be significantly worse and significantly less quality in the US but they will get better and that's the thing we all need to acknowledge and there was a policy at some point which was made which just told Huawei they will need to produce their own chips right and that's that's just a pathway going down here and I think there's like no going no going back here the question is like what do we do in the meanwhile right and how big would a gap potentially be and I'm a firm believer that this will be quite a massive gap which will have big impact on the AI competition. I think that is one of the key lines of debate but also you know empirical questions that's hard to really research or get hard data on which is the decisions of the private tech firms in China the the Alibabas the Tencent's and and others because the extent that you're right that there's a meaningful quality difference between Nvidia and Huawei GPUs for example they got a strong incentive to build as much as possible on on Nvidia so you can see an argument that says well they're gonna buy a Sense but sort of put them in the closet or not really take them seriously because they want to build their products but but you're saying no that's probably not the case because even those firms which don't have a strong incentive on their own to help out Huawei do in the context of potential future export controls and loss of access to an Nvidia chips and so the argument that that controls sort of align the incentives of Tencent and Alibaba with Huawei the Chinese state you think those incentives are already at this point fully aligned. Yeah I think so I think more more importantly here we should just always I mean let's walk through the arguments for it. There are arguments in favor of selling H20 and I think that's the same debate to be had here right. On the other side I think it's sometimes lacking some technical details here. I think the market share argument is a fair argument right just like you want to maintain for Nvidia a bigger market share and reduce demand for Huawei. I just don't think that's the case right it is an existential priority for China to produce the semiconductor industry and importantly it's not like the semiconductor industry only gets better because of AI chips. The majority of chips the world produces are not AI chips. Who's producing at the advanced node at most advanced node at SMIC but also at TSMC? It's Apple right. Usually we produce mobile phones first there so they're pushing it forward anyways for the newest Huawei smartphone to produce probably soon something like a six nanometer node which will then be leveraged to produce better AI chips right. So even if you reduce the market demand right now semiconductor industry will get better and these will lead to better AI chips eventually right if they then just like transition to to this. And then also what is the tech stack argument here right. Sure we keep them hooked on CUDA right and it's a pain to go from CUDA to eventually MindSpot to the Huawei ecosystem and I think we can model this as like a one-time transition cost. Many American companies have done this. Google switched to GPUs at some point right and Frobic right now is using the Tranium chips on AWS. I think they they pay a significant amount of costs here to switching and like running these different hardware stacks but eventually doing it right and they will also eventually do it with Huawei and it's not like if you use CUDA your systems are not more aligned you know like if you would sell them AI systems who don't spit out CCP propaganda. I'm in favor of that. That's like spreading American values, liberal values right. That seems fine but if you would be just selling them chips there there are no no values no constraints which come with selling chips. You can just do whatever you want on it right and I think that's again we're just like it's missing this tech set component and we kind of got it right in the UAE. Sell them the cloud let Microsoft build here versus here we just sell the underlying component they can build whatever they want on top of it. And I think that's just missing the debate. You've made it 30 minutes into a podcast about age 20s. Do you want to do this full-time? Do I have the opportunity for you? The Horizon Fellowship provides a direct path into the world of emerging tech policy. A fully funded placement at a federal agency, congressional office, or think tank in DC for up to two years. For its 2026 cohort Horizon is actively seeking candidates with expertise on China's technology ecosystem, its policy landscape, and broader strategic goals. Prior technical or policy experience is not required. Join a community of over 80 fellows working on some of today's most pressing issues that I can personally vouch for having met a good chunk of them are some of the smartest minds working on these topics in DC. The application deadline is August 28th. Check the show notes for a link to learn more and apply. I think this is a key aspect of the export control debate which which is fascinating a lot of people don't get is that if you if you restrict sales of tools then you hurt the toolmakers but you help the users of those tools. And so in the chip industry if you sell fewer lithography tools it's bad news for ASML but it's actually probably good in the long run for DSMC and other companies that face less Chinese competition. Similarly if you sell GPUs to China it's bad news for GPU sellers. It's good news for GPU sellers but bad news for US AI firms who face stronger competition. And so one of the kind of strategic questions is which level do you try to cut off? And the US has I guess decided until recently cut off at multiple levels and is now shifting, well I guess we'll see where we are next week, but this week it seems like it's shifted towards a policy of sell the GPUs but keep the controls on the chip making tools. Which makes sense right? Like if you would like reverse selling them extreme ultraviolet lithography machines from ASML it would be way more on a rampage than selling them AI chips right? And I would sort of complain more if we start selling them black wheels over age 20s right? So I think I think that's a fair debate we should be having here. People can fall on different types of positions here and again we can disagree on some arguments here and like again yeah and then you have like these different types of controls which I expect with each other and the AI chips are the first ones to fall and I think that makes sense. So yeah so it was one of the arguments is that if you make China addicted to AI chips you gain long-term leverage and I think like the mental model that people think of here as well if you get them using UV lithography tools they don't have their own ecosystem and it takes a decade to try to replicate your own tools. So maybe this is going for Lennart does the same dynamic hold here or is or if not why? What are the differences? Yeah I guess there are many different facets to being being addicted to something right? I mean in the ideal case it just means all Chinese firms are like really reluctant to adopt Chinese chips right? And therefore they have like less revenue, SMIC is wondering nobody wants to buy their chips and instead all the Chinese just buy US chips. I already talked upon how just like SMIC and semiconductor gets anyways independent of AI right? But it's a fair thing to say like the less people use like Huawei's AI software ecosystem the worse it is. I think that's that's a fair argument to be made. I just think they know they want to produce it anyways they just know we need our own AI chips at some point. They're not full steam on this I think that could go strong if they wanted to. Maybe they're full steam on it but I just don't do better for many reasons. So like them using the US tech right now I think like maybe delays it to some way even subsidize it. Let's just think about I don't know Volkswagen you know my German heritage they love to sarcastic China. How's this going right now? Did this stop BYD? Not really right? And I expect like the share of Volkswagens being sold to China right in the future will be low. The argument to be made here they made a ton of money in the meantime and I think that's a fair argument to be made. The reason why I just feel nervous about AI chips is well you supplement you'd like increase the total compute deployment training capacity in the time. If again let's just say AGI is a singular point AI is just not going to matter a nice five years then all we discuss it doesn't matter that much right? Because the good thing about AI chips is they get exponentially better. We're not going to talk about H20s in five six years from now because we have exponentially better chips already here right? So I think that's an argument we can just say like don't worry man we just sell them we make some money they get a little bit better AI but AI is not going to be decisive in the next four to five years but then later ideally then later we stop it right? And we don't sell them you have like better chips it's like exponentially better. Again it goes back where do we draw the threshold and when and how does AI matter which is a diffuse question right? And I have a pretty uncertain view here. I'm just like man AI could be a really big deal in the next three to four years it seems likely it's going to be a big deal bigger or less big right? Depending on how it goes from just like like transformative economic growth being like determine the future of the military up to just going to fizzle out right? I think we should address this uncertainty here. I just work on national security risk and I'm trying to minimize downside risks right? And I don't see see the benefits here in the long run that why we should sell them. So fair argument I think there's some good arguments here but overall I think it doesn't cut it at least for me. When you look at some companies like it's a really big deal having Chinese market access like Nvidia excuse me like Intel like 35% of their revenue is selling CPUs into China. This was a big deal for the tool manufacturers like you know in some years it was 30-40% over the past few years. Nvidia is a four trillion dollar company like they will be just fine and still be able to deliver you that exponential curve of you know rapidly improving AI chips even without you know the extra ten billion dollars of sales. I mean I guess you know there's like the maximalist version of this question of like okay like you are a hundred percent sure that AI is not matter does not matter and is not a sort of like strategic technology then yeah sell it you know go crazy you do whatever you want with it but it is it is a it's like a it's a it's a tricky line of thought we're like a you know we're writing an AI action plan where we want to make AI dominance we think this is gonna usher in a new golden age but we're willing to like take some of this downside risk that we're making it easier on a China which we've identified as a like like major strategic threat in order to I don't know what I mean we're still yeah well it's like it's like okay so if we if we do think this is a big chip like there is a broader context of the relationship that you can try to trade things in right and say you know we wanted them to scuttle some submarines or you know stop messing with the Philippines or I don't know there's just there are lots of other asks you can make from a sort of like balance of power regional dynamics perspective that you could have put on this and it's kind of wild that it didn't even seem to be in the context of the of the debate of the sort of discussion between the the US China trade deal but was just like a decision that Trump made independently because Jensen got to him and we wanted to have like good vibes in the relationship and the 15% tax we're putting on it I mean is it just going to like pay off the national debt I mean what if it went to like buy drones for Taiwan or to sort of shore up you know go into funding BIS so they could do a better job of tracking down all the chips that are getting leaked out into China you know there are some sort of lines of this where if you really are going to follow the like okay like we're all right with the premise that like China is a strategic threat and we got to kind of watch and and hopefully shape just how much they're going to gain on the US from a sort of relative technological competition perspective like there are other moves you can do to make it more to just sort of like use this card more in your favor than just like letting the other side pocket it. I think John that's an excellent point right and if you would just have like more insight here because what we've seen so far is the H20 got sold again then postdocs somebody said it was part of the trade talks others denied it then the Chinese came out denying it was part of the trade talks right and eventually what I don't like about it export was a national security thing right when the diffusion framework came out and there were certain countries like Poland, Switzerland in this tier 2 many were complaining like you're dividing European trade union but it's a national security thing it's not a trade deal we're doing here this is at least where export originally came from right and now we're mixing them with this trade things and now we get 50% of the revenue share and amazing let's pay off the debt let's do other great things I don't think national security is for sale here right if we would get like other national security concessions here in return that'd be amazing right it would just be nice to hear more and communicate about this there's definitely things where like people like me and others are willing to walk back hell yeah let's sell the H20 because we got a beautiful deal out of it I just don't think 15% of the sales is makes the cut here just money money doesn't help you they get the computing power you make money you might even make more money because there is Nvidia making money and maybe Microsoft or your favorite hyperscaler in between right why you still have more control and more leverage right so I still generally think I think many just miss the point you don't need chips like in your basement to run them you just access them remotely and so they could literally dial in they could dial in into our beautiful new UE 5 gigabit cluster or dial in in the US and like existing cloud providers and then in the future in case they go rogue or you really want to make sure it doesn't go to certain military linked entities you just have way more leverage right and I think like if we do the concessions we talked about the different things you want to walk back before you sell sell chips just tell them you can use the cloud which is by the way perfectly legal as we're speaking right now so if they really want to the computing power use our cloud still legal you can go for it we still make money so a little economy dynamic here which which Leonard I think you're you're referencing which is you know getting back to if you sell the tools you enable the chip maker if you enable chip makers that type of competitive dynamic and and what we've seen is GPU sellers and video I think most prominent be very vocal on this issue we haven't seen hyperscalers be vocal at all even though I think one should conclude this implies more competition for them and then we've seen mixed responses from AI model companies I think anthropic has been pretty vocal opposed I haven't seen open AI and so it strikes me that companies that have a lot of stake have been taking very different strategies some being vocal some not I don't know what exactly explains that more observation I got an explanation go for it you know which GPUs they're using and videos and if you speak out against them Jensen's gonna get you right so if you look at anthropic who's like slowly migrating to like more Google GPUs and Amazon Trinium you can see the deals they can speak out against it where everybody else is like I'm reliant on Jensen and I can at least confirm from many conversations with many people who's companies the only competitor here is AMD right and I think it's only gonna be the market share for NVIDIA is only gonna go downhill from here right the total market will go up AI is a big deal but AMD is getting better Google GPUs getting better Microsoft chips getting better Amazon chips getting better we have more and more startups getting better right we just have way way more AI chip competition I think like NVIDIA is also like slightly nervous on all of these issues and I think I would love to live in a world where NVIDIA had a smaller market share and see what the hyperscalers and AI companies would say and I think many of them would actually come out and open AI at least came out in favor of export controls historically when I talk about energy dominance and more and I think right now they're all just all quiet because somebody else might then knock on the door. It's fascinating in the context of I've gotten lots of questions of what does industry think and of course you know you're saying is well which part of industry are you looking at which which segment which specific companies yeah fascinating political economy there. Jordan back to you. Why don't you do that why don't you do the the HBM political economy this has apparently been reported that the Chinese government is asking for high-bandwidth memory as part of concession number two maybe like what would that what is that what does that tell you Leonard? If I'd be running China I would ask for high bandwidth memory over asking for H20s personally right because I've got my sovereign drive anyway so I want to build better and better AI chips and if I look at my current AI chip industry I would like to want EUV but maybe this is too much to ask for right because we did this early on Trump did it back in the days but what is the thing we've only recently done is banning high bandwidth memory units right so we got our chip and next to the chip we put like the memory and these memory units being produced by Samsung and SK hynix and micron they're not allowed to go to in China anymore right and we've seen reporting that at least the Chinese again the Chinese put forward could we trade HBM is that like something we can do here I hope the US government will draw like a clear red line here right we talked about how you would walk back things there are arguments in favor of selling your chips we talked about them what we do here is not selling them our chips we do here is enabling them building better chips the best way how the 910C or the 910D whatever the next best next chip is to produce will get better is by having higher bandwidth memory and right now China does not have the capacity to be to use even HBM3 there's reporting about first trial production of HBM3 in contrast Nvidia and others are starting to equip HBM4 and using HBM3 right now so again don't get wrong China will get better that will eventually produce high bandwidth memory there's lots more to be done they could stop them from producing better memory but in the meantime while they're like scaling up this production trying to get better at least we should probably not sell them our high bandwidth memory to make their chips more competitive because we might regret this in many years where we then competing of course emerging markets and Huawei has a better chip which can better compete with our chip and the interesting dynamic the memory space is that the two of the three producers are not US but Korean so it's also why we see probably tons of smuggling here because it's pretty close by and there's like certain tricks to get more HBM so don't get me wrong I think China smuggling HBM right now which is for sentinel gears but again I'm a favor throwing sentinel gears and ideally we get better enforcement so yeah they get less HBM eventually should we switch to the political economy of this in China so July 15th we get the news that the Trump administration is letting Nvidia start to sell h20s a week later MSS publishes a notice to the public saying to beware of digital spying via foreign produced chips ten days later the CAC the cyberspace administration of China summons Nvidia representatives over risks of being able to control a Chinese remotely and accuses them of having a kill switch in them then we have a private leading cybersecurity research firm in China Qianxin they publish a report which goes viral talking about all the ways that there could be back doors and ten days after that so just three days ago August 9th we have state television doing a whole big report talking about how there might be back doors already in these h20s and they cite a former Chinatalk guest Tim Fist's CNAS report on this topic which he came on to talk about on Chinatalk a few years ago so you're welcome I don't know Chris what's your what's your read on this like kind of interesting brushback pitch we've gotten from the central organs about h20s in China so I think there are three potential explanations not mutually exclusive one is that the Chinese security services are paranoid and the discussion in Washington of the chip security act which would mandate geolocation verification which has been happening simultaneously to the h20 debate has intensified those concerns that that's explanation one explanation two is that it's part of an effort to discourage the private Chinese tech firms from using h20s and that there are people around Huawei or in the government who are afraid that h20s will actually take into the market share and so this is a way to say buy more Huawei chips as well and then I think the third explanation is that there's actually pressure on US firms like Nvidia to say actually we need you to do more or else we're not gonna let you back in the market we've seen this in other segments of the tech sector where China will ramp up pressure on a private US firm with the aim of having that firm then try to use its resources to shift the debate in Washington you could maybe envision the HBM debate being part of what China is looking for the broader trade negotiations that are underway but it certainly wouldn't be a very attractive endpoint for Nvidia if they got approval from the US side then didn't get approval from the Chinese side to sell so perhaps China thinks it has some some leverage there how exactly to kind of tribute these three causes I'm not exactly sure what the what the shares I would put on each of them but they both seem or all three of them seem potentially relevant. Did we talk about also put out guidance a while ago on energy efficiency this was actually shortly in April or May when the H20 was no sorry even before so when the H20 was sold before it got banned initially they put out guidance that the H20 is famously pretty energy inefficient if you look at flops right because of the export control bandwidth and basically I don't know exactly what this guidance means but basically discourages companies from using it I guess nobody's been following it because now they're buying it and in the well up in the single millions and the ship but I think it feeds into the same narrative here right just like you try to push certain companies or you create artificial demand for like some Huawei chips like slowly tell them like hey guys at some point we want to do our own AI chips right I think as Chris was saying I think all of these stories are simultaneously true right I think it all just makes sense and there's like no big downside for them to do these kinds of things only benefits. But actually there was the same media source I don't know if Sony you're referencing Jordan but but one of its criticisms of the H20 was that it was environmentally unfriendly. Yeah no they cite this exact NDRC line that Leonard talked about how the goal is five teraflops or half a teraflop per watt and the H20 can only give you 0.37 so pretty bad pretty environmentally unfriendly for training but pretty damn environmentally friendly for deployment of AI chips way better than any Huawei chip I can tell you that. I mean I think like here's a moment where some mirroring might be in order we've just had an hour-long conversation about how messy and convoluted and sort of like how many conflicting priorities we have in American policy towards artificial intelligence and like the same thing is happening in all these different ministries in China and you know this is big news this is like a a change in the landscape and people want to you know people want to have their say and make their stamp on it so you don't necessarily need to sort of like attribute some like 4D chess of like oh now's the time to squeeze them but like I'm sure the people in the MSS read Tim's thing and are like oh this would be really stupid if we bought all these chips only for them to turn into you know bricks or like spy on us or like have bombs in them that are gonna blow up like beepers in Lebanon or something I'm sure folks in CAC feel the same way and then you know the same debate that we've been having for the past hour of oh is it sort of like net positive or net negative for domestic self-sufficiency like to have a sort of competitor to Huawei potentially take a big chunk of the market domestically is something that's that's being played out in China so I agree with you that like at a broad level now is the right time to ask for more stuff from Nvidia that now that they've gotten the green light and there is this kind of you know 10 10 15 billion dollars of demand and these chips sitting on a lot somewhere in Taiwan that they're really excited to ship out to say hey you know you know you better step it off or cut the price or you know do do an extra screen to make sure there aren't any kill switches on it or whatever you know the way this is playing out on Twitter is oh China saying they don't want them that means we should definitely sell them I don't think it is necessarily just positive just reading that Chinese state media or state organs are saying something means it is true I mean there is it's not that hard to play the let's not even give this credit for 40s chess this is just 2d chess of saying oh no we're worried about the chips we don't even want them chips that changes the political economy of the debate in Washington where it makes selling these chips potentially easier to go down so that's also something to watch out for as we see the Chinese government saying I know we didn't really want these all that much this isn't actually a big concession we're kind of worried about the knock the second-order effects of this but the fact is people like the demand is not going anywhere like it's not like Alibaba's not going to buy these chips because because of these sort of warnings I think I think Alibaba would be pretty sad if they suddenly only need to rely on other inferior chips where they can't produce enough of them right like ideally and if I would run the Chinese government I would like put out so many regulations that I can sell all of the Huawei chips I can produce and then fill the rest with like some nice Nvidia chips here but I think also it's interesting I think there's just some misunderstanding about the chip security act is supposed to do and location verification the idea is not to check if a chip is well the idea is to check if a chip is in China and then we have a problem right so idea is like we put this tracker on a chip in Malaysia Singapore wherever you think that we smuggled and then check they don't end up in China right so this was never supposed to be go on chips which go to China because ideally we don't have any chips going to China at least not advanced ones right so this is an interesting confusion right like this whole debate of this hardware name and mechanism location verification was big in the UAE and Saudi Arabia and Singapore and Malaysia for all of these smuggling hotspots which people were worried about and again I think some people have been pushing and I think if you think about if we now stop selling chips I'm arguing we should sell them cloud that's one line before people could say we can sell them chips but put something on the chip right but like just knowing a chip is now in China and we know it's in this location and this city over there how does this help us again here right again like and then everybody can dial in remotely even if it's a Tencent who says that the PLA is not using it right you can just dial in remotely so I don't know what's going on there after some misinterpretation of documents just some vibes it's it's a confusing status. Jordan you previously made a point about Intel which I think is an interesting one we're like saying like Intel made a lot of money in China right and Intel is still allowed to sell their CPUs and Intel CPU share in China is only going down right and I think we will see the same with with Nvidia and AI chips basically even if you're allowed to sell your share will potentially be going down why is this a case there is similar guidance for example for all government computers to go to a homegrown domestic produced chips we can't trust Intel anymore on this right we will see the same on AI chips so yes Intel made a lot of money in China but the share is going down over time and they're pushing on the self-reliance basically to produce their own AI chips and they also named security concerns here right that's why the government is coming first I don't know the exact numbers of Intel's sales right now in China and how much money they're making there but I'm pretty confident it's been going down and the government is not buying any more Intel chips because to just put out this guidance here so we seen this playbook playing out before right the only difference is now we have this confusion with which chips are allowed to be sold which ones are not to be sold and how good are they actually right but the story is nothing new can we talk about what we know in terms of the big buyers of AI chips in China and their relationship with the state so you got the private you know quote on private tech firms Baba and Tencent you've got the AI labs you know deep seek most prominently I don't know what Leonard Jordan was you have a view here but one of the key questions seems to be how what is the relationship with the state today and how is it changing and to what extent should we see them as you know arm of the state is certainly not accurate totally independent is certainly not accurate there's a spectrum and so to what extent are these political priorities shaping their procurement decisions look there was reporting which was clearly sourced by the intelligence community over the past few years that after the MSS hack of the SF 86 so that's the form you submit to the US government when you want a security clearance which like talks about you which basically like you try to you know it's your like confession of sorts to the Catholic Church where you talk about all your divorces and all your debt and everything you know that a foreign intelligence community might want to know about you that that data was actually that the MSS tapped Alibaba and by chance engineers to sort of like put into a more useful format so um like we've just seen over the past few weeks reporting for business insider about a public tender from some corner of the PLA that wanted h8 h20 is to like do whatever they wanted to do with it I used to be more sanguine on this type of thing but I think there's again this is like the most this is the dual use technology to like beat out other dual use technology so it just seems to me to be like a little preposterous that like insofar as this is a strategic resource that the Chinese government would not be able to leverage you know data centers that are living in China that the US did not have any sort of kill switches or on-chip governance on in order to do whatever they want to do with it whether that's you know build a surveillance system or help with weapons manufacturing and to be clear like you know the Pentagon has now signed like I think it's like a 200 million dollar contract with open AI and that this is just the beginning right so like clearly this stuff is useful that we're willing to pay a lot of money to like get it into the Pentagon and in one form or another so if what we're sort of convinced with if what you find what Leonard says is convincing is that you selling a lot of h20s like materially raises the amount of sort of like usable functional compute that can be put into anything in China it would be really surprising for me if you didn't have the Chinese government want to take out these new toys for if you didn't have this sort of Chinese like military police complex want to take these new tools out for a spin so I think there's kind of two two two points you get on so one is if AI tools exist will the military use them and I think the obvious answer is yes there but I'm on the prick if you're a data center procurement official or executive at Alibaba cloud to what extent is your decision-making they're shaped by what you read and state media versus what your boss tells you to build an effective cloud in which case maybe a swings are your best option versus the sense again how do we think about the because those are the people are going to decide how many cents to buy right unless they're getting a dictate we maybe are from the top now I guess like the sort of counter example I'm thinking myself is you know there was a time when parts and maybe still don't know parts the u.s. military were using Chinese drones not because there was a policy these Chinese drones because they didn't have any u.s. drones and so I is there a scenario in which like your your procurement executive at Alibaba is is it's just gonna ignore the sense because they told the building a center yeah I think I think I at some level yes I mean these are these are companies that report quarterly earnings that pay their employees based on how well the company performs right and you know people get stock options so I think by and large the the the incentives of the people who are buying these chips is to you know drive the most revenue for the money you're spending on your CapEx but you know it only goes so far and I do think that there is this sort of broader strategic realization which you don't even which you don't need Beijing to tell you right is that this is like a this is this you know this door can be closed at any time and you know it's closed it already so you know yeah I mean I think I think maybe now is an interesting moment to sort of talk about the sorts of things that could change the dynamic we're on now on chips and sort of on the broader US-China relationship I mean we have Congress as a variable there have been a number of senators and Congress people who've been like wait what are we doing selling these ships to China I thought we banned and said we're you know you know our our our golden ticket to the 21st century and then I think just because Trump is doing this at such a personal level like we've seen him turn on Putin right and I mean we've seen him gone from gone from like all Putin to like we're gonna ask some questions about this guy and you know we'll see what the hell happens in Alaska but I do think that there is like Jensen saying the wrong thing taking too much of a victory lap or you know she doing something really obnoxious I mean there's there are a lot of sort of like personal interpersonal dynamics that could change what the what the Trump what the Trump administration ends up doing which is like probably the more relevant variable than like whether or not Leonard can convince you that how I can only make X amount of chips it's an interesting moment of time because we just have all of the trade negotiations right so everything is like volatile and it's just like certain things are just on the table and they'd be willing to discuss them right and we see the Chinese bringing forward at least according to reporting the idea of HBM right and it will just be interesting to see what the government is going to say it's going to draw a red line we had statements before the trade negotiations in London that H20 is above the red line right so they wouldn't negotiate it and again we can all try to put together the story what happened here what not if it's part of it we we won't know for sure right but it will be more discussions about these kinds of things the Chinese can bring it up but I'm also more interested in the semiconductor manufacturing equipment companies if NVIDIA got this beautiful deal I know what we're doing right they're all trying to give the president elsewhere a ring and it just seems like it's a handful of people are making these these decisions and I just hope they're like well informed of which things are more important right if if I see any news about EUV machines being sold to China I'm probably going to get a heart attack and I just really don't want to send I mean I think just from a personal transaction perspective like there isn't someone in the semi-cap equipment ecosystem that Trump's gonna give the time of day like he felt like he had to with Jensen because you know this is like America's most important CEO I don't think any of those folks have this sort of like panache and skill yeah it work and even you know Ben Thompson who I gave so I gave a hard time for earlier in this podcast understands very clearly that there's a lot of downside risk in selling more tools to China than we already have I would go even so far it wouldn't be good for Jensen if Huawei is not good at producing AI chips right so wouldn't wouldn't be in the interest to say like hey yeah let's make sure we set them all chips or really let's make sure to hit them on every single dimension we can to make sure Huawei is just less competitive right I would love to see that this would be at least a good part of the story here I think the way to Congress I think Congress will be interesting to watch on this issue because you the trend in Congress has been Congress has vocally pushed for tougher controls both in the first administration and under Biden not universally but I think that's been the predominant push and so now I think we'll be interesting to watch Senator Cotton for example and and what he does it does not say publicly on on this issue Chris do you want to sort of tie the you know tease out the Russia comparison a little bit I mean Congress like really not happy they ended up putting some sanctions on the table what was the what are the dynamics been there over the past six months well I guess the last six months in Russia have seen Congress officially not play much role at all they put sanctions legislation on the table and pulled it back actually for Trump requested it but I I think I would say there's been a number of Republican senators who have been influential in shaping Trump's thinking Lindsey Graham for example seems to play a role in shaping Trump's thinking on Putin over the last six months and the way that Putin is stringing along now you know we're going to Alaska later this week and so maybe all that will prove irrelevant if Trump changes his mind but it does seem like you could argue that that even though Congress has done nothing on Russia in fact it it has helped change thinking in the White House I wonder if the same will be true here but but this seems like a place where Trump's going to make more of his own decisions especially as far as it intersects with the China trade negotiations which it seems like it may well yeah and it's it's kind of a less salient thing than a land war there's no domestic land yeah yeah just weirdos tech national security podcasts um other stuff we should get to Leonard do you have anything to say about the um is before before this week it was reported that Nvidia is coming out with a downgraded version of some new downgraded chip post h20 but I guess that's oh yeah the b40 or b30 I think yeah that's now irrelevant because of the h20 it's unclear right if people we flip-flop the decision on the h20 but notably there is still a license requirement right so Nvidia got the license granted so if they wanted to go all the way back they could have removed the license requirement right so from October 2023 to April 2025 there was no license requirement then they introduced a license requirement which is still intact the only thing which happened as of speaking last Friday's they granted the licenses according to reporting right so if they still want to set a chip which is not subject to expert controls that would produce a new chip called b30 b40 it needs to be low to computational power threshold so the same as the h20 and also have lower memory bandwidth and according to the reporting I think FT leaked what is in the form letter it needs to be less than 1.4 terabyte per second memory bandwidth again the h20 is at 4 terabyte per second right so the b40 would then probably not use HBM anymore it would probably be used to like an inferior memory technology but significantly cheaper because why use HBM if you can't have that many memory bandwidth anyways so-called GDDR technology which we usually use for graphic GPUs and again if people talk about this is only the fourth best chip I don't think the h20 is the fourth best chip I think the b30 b40 that's a more fair description of a fourth best chip and I would still not call it an obsolete chip but it's definitely a worse chip it's only like you know with a chip where like again the US government at least decided here's where we draw the new lines this chip is fine to be exported before license so could still be coming I have not heard they're stopping the production yet I guess NVIDIA's making a calculus right now on how much demand there is but it's clear the case the h20 is better the question is will all the licenses be granted going forward right and Trump has said or he said at the press conference a couple days ago that he'll consider a downgraded Blackwell mm-hmm are there ways we should think about what that might look like if in fact the material materializes of course with huge questions over whether or not that's actually real one thing which set out he said like 30 or 15 to 50 percent less performance and I think what many people are just missing on on AI chips and computing chips get exponentially better if your chip is 15 percent less that's nothing that's still the same generation right so if you really want to sell worse chips you need to go back a few generations and then the chip needs to be like seven times worse not only 50% or 15% right so there's an argument to be made that you want to sell worse chips but it's not a little bit of a downgrade we really need to take the exponential into account right if we trim down a Blackwell chip for example a b200 by 15 to 50 percent still like twice or three times as good as the Huawei chip right and again we can produce millions of them but Huawei struggles according to reporting producing 200,000 this year so again that's just a key thing to get right here and yeah people keep in mind exponentials here right like chips get exponentially better at 15 to 50 percent trim is nothing in the grand scheme of things and I would at least yeah make my voice heard to say this is this is probably not a good idea of what should be doing here the government drew lines before and the lines are way lower and I think that's where it should be all right well been a long road since October of 2022 thanks for sticking with us everyone this information is for educational purposes only and is not a recommendation to buy hold or sell any investment or financial product this podcast has been produced by a third party and may include pay promotional advertisements other company references and individuals unaffiliated with a 16-z such advertisements companies and individuals are not endorsed by a age capital management LLC a 16-z or any of its affiliates information is from sources deemed reliable on the date of publication but a 16-z does not guarantee its accuracy


---

## 2025-08-13

### Grok, Genie 3, GPT-5 & the Rise of Vibe Coding
**Publication Date:** 2025-08-13T16:59:53
**Episode ID:** 5080

**Full Transcript:**
It's sort of huge that you can click one button and get a video on your phone in less than a minute. You can't just scrape data from the internet, like the record labels will come in to you. It's sort of one of the first really truly social kind of forays into AI image and video generation. Now when you post a photo on X, you can like long click and press and immediately turn it into a video. The fact that someone who's completely non-technical can build something that a couple thousand people can use overnight is like amazing and so exciting. None of the existing social platforms have leaned that heavily into AI creative content. And a lot of the AI creative tools I think can and should and will sort of integrate more social. Things in consumer AI are moving fast. In this episode, Olivia Moore and Justine Moore, creators and partners at A16Z, break down what's new and what's next across the consumer AI space. You'll hear about the latest updates from Grok's Imagine and what makes it so different from other creative tools on the market. They break down the release of Genie 3, Google's new 3D world model, and why it might be the start of an entirely new kind of gaming and media format. And of course, they discuss GPT-5. Not just what's new, but what's missing and why some users want their old chatbot friend back. Along the way, we'll hear about AI-generated music and Olivia's very own vibe-coded selfie app starring Jensen Huang. Let's get into it. Welcome back to This Week in Consumer. I'm Justine. I'm Olivia. And we have a bunch of fun topics we want to cover this week, starting in the creative tools ecosystem with Grok Imagine. And then we're also going to talk about Genie 3 and the 11 Labs music model. And then we'll cover GPT-5 and the deprecation of GPT-4.0. And we'll cover our new vibe-coding thesis. So this week, we are going to start with Grok, which has had a bunch of big updates over the last month or so, I'd say. So obviously, Grok 4 came out. The Grok Companions caused a huge stir, particularly Annie and Valentine. But I think more recently, what's been really interesting is all of the image and video generation features on Grok Imagine. Yeah, so Grok released an image and video generation model called Imagine, which is offered standalone through the Grok app. And they're also bringing it to the web. And it's now embedded into the CoreX app as well, which is really exciting. Yeah, I think that's one of the things that's really unique about it. I would say it's not the most powerful kind of image or video generation model that exists. Elon has tweeted a bunch about how they're training a much bigger model. But I think what's really cool about it is it's sort of one of the first really truly social kind of forays into AI image and video generation. And what you mean by it being integrated into the X app is like now when you post a photo on X, you can like long click and press and immediately turn it into a video animated in the Grok app. Or even if you see someone else's photo posted on X, you can turn it into a video or also edit the image with Grok, which is really exciting. Totally. I think one of the coolest things about Grok Imagine, to your point, it's not the most powerful model. It's not VO3. On video, I would say the audio generation is okay, but not great. But it's fast. So fast. Which I think for a lot of people has been kind of the real barrier to doing image and video generation more seriously. Is you put in a prompt, you press go, and then sometimes you're waiting 30, 60, 90 seconds for a generation. Yeah, often minutes, honestly, for a generation. And Grok images are basically instant. Yes. And the videos are pretty fast as well. And so I found myself iterating very frequently. It's now become in less than a week like my go-to tool for image generation on mobile. Yep. And even the video, I would say, is getting there, especially if they're training a better model. Totally, yeah. I think for many people, they're not professional creators. Yeah. And so they don't want to make an image in one place and then go and download it and then port it into another website. Because often very few other tools are on mobile, especially for video generation. So I think it's sort of huge that you kind of can click one button and get a video on your phone in less than a minute. That feels like a massive step forward for consumer applications of AI creative tools. And I think Elon and a bunch of folks on the XAI team have been tweeting about this. One of the big use cases is like animating memes or animating old photos or like things that you already have on your phone. Yeah. Because you can access the camera roll so quickly through the Grok mobile app. Yeah. It will also generate real people. Yes. Elon has been tweeting many imagined generated photos and videos of himself. Yes. Which I think is another big differentiator. Totally. And something we've really only seen from VO3 and even then it's mostly characters versus celebrities. Yes. But it comes from Grok's kind of uncensored nature, which is pretty, I think, cool and unlocks a whole bunch of new use cases. Yeah, for sure. And I think that allows the meme generation. And even VO3, half the time I try to do an image of myself, it'll be like blocked due to our prominent person thing. And I'm like, what do you mean? I'm not a prominent person. But like in that photo, I guess I look too much like some celebrity or prominent person and it decided to block it. And I've never had that problem on Grok, which makes it just so fun and easy to play around with. Yeah. I'm excited to see where they take it. It feels like we've seen Meta experiment a little bit with kind of AI within their core products. They've done the AI characters you can talk to and then uploading a photo to get an avatar where you can generate photos of yourself. But none of it felt quite right, I would say, in terms of baking into the core existing experience on Instagram or Facebook. And Grok feels a little bit different. So I'm excited to see where they go with it. Yeah, I'd say none of the existing social platforms have leaned that heavily into AI creative content. And a lot of the AI creative tools I think can and should and will sort of integrate more social. But today, most of them have just done relatively basic feeds and liking, not really comments, not really like a following model. And so I think this is going to be a super interesting proof point about what a more social AI creative tool looks like. Great. The other big model news of this week, which is not just big for consumer but for pretty much all of AI, was the GPT-5 release. Yes. And then the corresponding deprecation of GPT-4.0, which I think ended up being even bigger news in consumer land specifically. Yeah. This one was sort of fascinating because obviously it's been a while since OpenAI had had a major LLM release since GPT-4. And so people were like very eagerly awaiting GPT-5. But yeah, as soon as I got access to GPT-5, I wanted to compare the outputs to GPT-4 and I immediately noticed GPT-4 was gone. Yeah. And so how are people – because I've seen a lot of posts of people kind of up in arms about 4.0 disappearing. How would you describe kind of the main differences between the models, at least how they're manifesting in user experiences? Yeah. So I've talked to a bunch of folks about this. I think a widespread conclusion is GPT-5 is really good at – especially like front-end code. I think a lot of the model companies are really focusing on coding as a major use case, a major driver of economic value, something they can be really good at. And you can tell in the results from GPT-5. And they emphasize it in the live stream pretty significantly. Totally. Yeah. And you can see from the examples people use it's much better generating things. It's much better debugging, et cetera. But a lot of consumers aren't using it for code. A lot of consumers just want to chat with it. And there's a bunch of examples of how it's a lot less expressive, emotional, and fun. Like it doesn't really use exclamation points. It doesn't really use emojis. It doesn't send things in all caps like it used to. It doesn't do the classic 4.0. It's not just good. It's great. Yes, exactly. And I think there are kind of two separate issues here. So one is the sort of like glazing excessive validation. Like it said like, you're the best. You should totally do that. That's the best decision for like everything you said, even if it was ridiculous, which is like a problem that I think I'm glad they're working on and getting rid of. Because let alone like everyone's concerns about GPT psychosis or whatever, you just can't trust something that always tells you you're right. The second thing is does it just have a fun and engaging and more casual human feeling personality? And I think that actually maybe took a step back from GPT 4.0 to GPT 5. And that is what people like if you look at the chat GPT subreddit. People are freaking out. People are freaking out. And I think that's why Sam sort of rolled it back. I think he actually may have announced this on Reddit in a comment in response to all of this backlash where he was like, we hear you guys. We'll bring back 4.0 for the paid users. I was actually kind of surprised they even got rid of 4.0. I know there had been a lot of jokes about what a pain it is to have to select the model and kind of the dashboard was always getting bigger. But they had even started building some UI around 4.0 image generation. They had some preset templates you could use. And so the fact that they didn't just add on 5.0 as an option but took away your ability to use every other model was a little bit surprising to me. Yeah, I think there's image generation on 5.0, right? Like I imagine some of the templates and the editing tools they plan to just move over between the models. They may not have gotten there yet. I think it's so funny because if you imagine yourself in the shoes of one of these researchers, you're like, we trained what is on the benchmarks clearly a much better model. It's smarter. It's better at math. It's better at coding. Yeah. A move towards AGI. Exactly. And of course, classic consumer is, no, we don't want that. Give us the old toy back. Give us our fun friend who kind of mirrored the way we spoke to it and was over the top and sometimes kind of crazy but was really fun to chat with. Yeah. I think to me, honestly, this exemplifies something I've suspected for a long time, which is I don't necessarily think the smartest model that scores the best on sort of all of these objective benchmarks of intelligence will be the model that people want to chat with. Yeah. I think there's going to be a huge market for more of these companionship, entertainment, just having fun type models that doesn't need to be like the highest IQ person you know. Yeah, I agree. I do want to spend 30 seconds on that mental health and health overall use case though. Yeah. It's interesting timing because also last week the state of Illinois just passed a law banning AI for mental health or therapy without kind of the supervision of a licensed professional. And it's pretty interesting because the law is wide ranging to the extent that some AI mental health companies have already shut down new operations in Illinois or kind of prohibited new users from signing up. Yeah. It's basically anything that's kind of ongoing support or even personalized advice around specific emotional and mental issues is now counted as therapy and is technically illegal in Illinois. Yeah. I am confident ChatGBT is doing this and honestly is doing it well. Yes. For a lot of people. And so I guess my question is to what extent is this ever going to be enforced because I can't see people's individual chats. I feel like Illinois always does weird stuff. Like we've been consumer investors for too long. And remember in like 2017, 2018 we would literally talk to social apps like consumer social apps that were like we launched everywhere except for Illinois because they have all these like crazy regulations around like people like data and sharing and like all of these things. Which obviously it's good to have those but like went way beyond other states to the point where it made it difficult for apps to operate there which is in my opinion then bad for the consumer. I think there are like a lot of people are sort of now grappling with this question of what does it mean for AI to offer medical support or mental health support. I don't expect we'll see the other states go in the direction of Illinois. Yeah. Partially because it's just so hard to regulate. Yeah. Like how can you control what someone is talking to their ChatGBT or Claude or whatever about. Well and especially because GBT-5 was kind of trained or fine-tuned at least with data from real physicians. Yeah. Yeah. So they talked about this a lot in the live stream and I was surprised they leaned in on this. I'm sure we've all seen the viral Reddit posts about like ChatGBT saved my life. My doctor said wait for this imaging scan. It turns out I had this horrible thing that I was able to get treated immediately. And Sam and Greg Brockman had been retweeting these posts for a while which I was like that's interesting because you think they'd from a liability perspective they'd lean out from that. Yeah. But they had a whole section of the GBT-5 live stream where they brought up someone who had cancer and was using ChatGBT to upload all of her documents, get suggestions about treatment, kind of talk through the diagnosis and what she could do next. Yeah. And they talked about how GBT-5 was kind of the highest scoring model on this thing called HealthBench which is a benchmark they trained with 250 plus physicians to measure how good an LLM is at answering medical questions. Yeah. And so I think it's kind of a really big statement that open AI has leaned into this space so heavily versus being like hey there's a lot of liability around medical stuff. Our AI chatbot is not a licensed doctor. We're going to kind of let people do this off label but we're not going to endorse it. Yeah. It seems like now they're really endorsing it. Yeah. I'm excited. Me too. I upload all sorts of stuff. Yes. And get all kinds of advice and it can be really smart and really helpful in a lot of cases. I agree. There were two other big actually creative tool model releases this week. Yes. Genie 3 from Google. Yes. And then a new music model from Eleven Labs. Yes. So maybe let's start with Genie 3. I've seen the videos but what is it? Yes. Genie 3 took Twitter by storm. Yeah. So Google has a bunch of kind of different initiatives around image, video, 3D world. I think various teams like VO3 and the Genie team working towards this idea of like an interactive world model. Yeah. Which is basically you are able to have a scene that you can walk through in real time or interact with that kind of generates on the fly. And you can imagine it sort of like a personal video game. Yeah. I saw some of the videos of kind of taking famous paintings and for the first time you're able to step into them and kind of swivel around and move around in the world. Almost like you have a VR headset on or something. Yes. And you're kind of turning around and seeing the full environment. Those were really cool. And it's not just famous paintings. They've shown a bunch of examples of from a text prompt you can create a world, from an image you can create a world. Yeah. Amazing. They've even shown taking VO3 videos and creating a world around it with Genie 3. And the cool thing about Genie 3 is there's controls where you can move the character around. So you can control like now go to the left and then the scene sort of regenerates to show you what you would see on the left. It's incredible. Yeah. And they haven't released it publicly yet. Okay. They invited some folks to try it out at their office who were kind of sharing results. They shared a bunch of clips. I'm personally really excited to get my hands on it. I think the natural question we've all had with this use case and seeing the demos is like, this looks amazing. Like, what are we going to do with it? Exactly. And it's expensive. Yeah. And probably takes a long time. Like, they haven't released the stats around that. How do you consume it? Yeah. Exactly. I think there'll be a couple use cases. I think video is an obvious one where if you're generating the scene in real time and then controlling how you or any character or objects are moving through it, that enables much more control over a video that you could then kind of screen capture what is happening than you would get from a traditional video model. Interesting. So you're almost recording the video. You're recording video as you move through the 3D world model, which then becomes like a movie or a film, essentially. Yes. And the video company World Labs has a really cool product out that I'm on and a number of folks are on that does this. And Martin on our team shares a bunch of really cool examples of stuff he makes with exactly that use case. Very cool. So much more controllable video generation, which is huge. I think in gaming, like, there's kind of two paths that this can go, and it could go both. One is it allows real game developers to create games much more quickly and easily where you don't have to kind of code up and render up an entire world. It can just generate from the initial image or text prompt you provide and the guidance you give it. And then you can imagine, like, could a game developer freeze that world and allow other people to play it like a traditional game? So it's like the game then would be the same for every person versus in the first example, the game almost regenerates for everyone fresh as they move through it. Right. Okay. But I think the second gaming example is more like kind of what you're alluding to, which is more personal gaming, which is like every person puts in an image or video or text prompt and then is sort of creating their own mini game where they're wandering through a scene, which is sort of a totally new market that I think a lot of people will love. And then the third example, which is a little out of our wheelhouse, but a lot of folks are talking about how creating sort of these interactive, dynamic worlds are really good RL environments for agents to be trained on how to interact with the world, like how things move, going around scenes, interacting with objects. It's been a big space of conversation right now, and sort of there's a desperate need for more. There's so many companies now selling these RL environments for agents that they're manually creating. And something like a Genie 3 could make that much easier and sort of allow you to generate unlimited environments for these agents to wander through and learn from. I could see that for digital agents, but even like physical agents operating within robots or something like that. Yeah, yeah, yeah. Totally. So for digital agents or like self-learning systems, it's going to be fascinating. That's awesome. So eagerly awaiting that one to come out. And then, yes, our portfolio company, Eleven Labs, also released their music model, which is super exciting. I did not know they were working on music. Yes, it's been in the works for a bit. The really interesting thing about it is it's trained on fully licensed music, which means – so music is one of those spaces where the rights holders are extremely litigious. Yeah. So compared to things like image or video, it's been harder for music companies to sort of avoid stepping on the toes. Yeah, because you can't just scrape data from the internet. Yes. Like the record labels will come and sue you. Yes, and the artists and like – it's often a very complicated ecosystem of who owns the rights to a specific song or to an artist's voice or something like that. And so, yeah, I think a lot of folks have thought that you could not get a good quality music model training on licensed data because it's hard and it's expensive and it takes a long time and it's hard to get them to agree to license you the data. But from what I've seen and from my own experiments, folks have been really impressed by Eleven's outputs. And so what does the licensed data open up in terms of use cases for the music model, do you think? Yeah, so I think a lot of consumers basically don't care if they're using a music model that's trained on licensed data or not because they're not really monetizing or many of them are not monetizing stuff that they make with this music. They're generating like a birthday song for their friends. Totally. Or a meme clip or something like that. Or like background music for their AI video. Yep, yep. Whereas businesses, enterprises, big media companies, gaming companies, like they care and they need to be able to say this music model we used was trained on fully licensed data to not kind of open themselves up to any liability issues. Yeah. So they could use this music hypothetically in like advertisements. Totally. Or films or TV shows or things like that. Exactly. Which I think is a big step forward for AI music as a whole. And I think we should expect to see more from Eleven on this front, which is very exciting. Awesome. And then our last big topic of this week is around vibe coding, which continues to explode. Yes. I think we have two things to talk about here. One would be our own experiments in the world of vibe coding, which relates to a piece that you and Anish Acharya put out this past week about how we're seeing the vibe coding market start to fragment. Yes. Your experiment is the more interesting part. So my... So let's start with that. Yeah. Maybe to give a real world example, for the first time I vibe coded an app that I fully published and made available to the internet. Essentially what I did was I thought, hey, I'm seeing on my XFeed all the time, everyone has a selfie with Jensen at NVIDIA. How did they get this? In his classic leather jacket. Yes. He must be spending all of his time taking selfies now because everyone has one and I don't. And so I was thinking there's all these new amazing models out there like Flux Context that can kind of take an image, say, of Jensen taking a selfie with someone else and put my... stick me in there instead. Yes. Replace me in the selfie. I should have been in the video. I should have been in the video, exactly. Yeah. So I did that. Yeah. I generated that myself on CRIA and then I thought, I bet other people might feel like me and might want this. Yes. And so I'd love to create an app where anyone can upload a photo and get a selfie with Jensen. Yes. And so I thought, okay, I can vibe code this. Yes. So I vibe coded on Lovable an app that connected to Fall to pull in the Flux Context API. Yep. Then you could upload your own photo, would generate the selfie with Jensen, which you can then download. I used it. It was great. Yes. It worked super well. So I published it on Twitter. Yes. A lot of people used it. It got used by like 3,000 people overnight to the point where when I woke up, I had exhausted my self-imposed budget of $100 to spend on API calls here. Yes. Because you were funding it. I was funding it myself. You weren't making people put in their API key. I was not making anyone pay for it or put in their own API key. So it was to the point where I had exhausted it. So instead of calling the model, it was just kind of stitching together half of your photo with half of Jensen's photo. Love that. To produce a really kind of 2005 Microsoft Paint looking output, which has its own charm. Which is an aesthetic. Yeah. Yeah. Anyway, but the surprise was, so one, the fact that someone who's completely non-technical can build something that thousands of people, and I did it in like a couple hours in an evening, if that, that a couple thousand people can use overnight is like amazing and so exciting. Yes. My second learning was, however, we're early in vibe coding because these products are definitely built for people who are already technical. Yeah, there were some issues. We had some issues. Which we should talk about. You should not expose your public API key. Well, the problem is you didn't even know you were exposing your public API key until some nice man DMed you and was like. So the vibe coding platforms are, I think they assume that you have a certain level of knowledge already. So if you go to publish a website or an application, they won't stop you and say, hey, here's a security issue. Here's a compliance issue. Fix this before you publish. Yes. And so it was a really interesting learning experiment for me, I think, first of like, I think there will be, and this is what you got out in your blog post. Yes. There'll hopefully be a V2, V3, V5 of these vibe coding platforms that are built for people who don't know these things already. So two things people flagged to you that the vibe coding platforms did not was one, your API key was exposed. Yes. And two, you had not created like a protected database. Private buckets for the photos. For the photos that were updated. So it was like if you knew how you could go and access the selfies that were uploaded. Yes. Yeah. And I've vibe coded many things. To be clear. Yes. I've had similar problems vibe coding a lot of apps where like, I feel like they assume you have a level of technical knowledge to be able to fix things or to even know what a potential problem could be. Yes. And so, yeah, Anisha and I published, Anisha was actually an engineer, and I collaborated on this post around basically how we think vibe coding will evolve in the future. I think today you have a bunch of awesome platforms that are trying to be everything to everyone. And I'm not saying like an engineer at a company can use this to develop internal tools or someone can use this to build a SaaS app that scales to hundreds of thousands of users. And a consumer can also use this to create a fun meme app. But I think the truth in terms of what we've seen at least is those are very different products, both in terms of the use cases, the integration, and the level of complexity required. And there probably should be, for example, a platform that is like the training wheels version of vibe coding for like consumer non-developers like us that does not allow you to make mistakes like exposing the API key. Even if it then means less flexibility in the product. Exactly. Like I wasn't super opinionated about what it looked like, all of the specific features. I just wanted it to work. Yeah, you probably weren't super opinionated on like the coding language or exactly what database was using, like all the backend stuff of what it was built on top of. You didn't really care. You just wanted it to work. Yes. Whereas there's many like enterprise or true developer use cases where they very much want to control every element of the stack and that level of inflexibility, that product would just not work for them. Yeah. And so I think what we are hoping to see basically is like specialized players emerge that offer the best product for a particular demographic of user or for a particular use case. Yeah. And that will probably imply very different product experiences, product constraints, and also go-to-market strategies. Like if you are allowing any consumer to vibe code like a fun app to share with their friends or partner or whatever, you probably want to be going viral on TikTok and Reels. Yeah. Versus if you are building a vibe coding platform for designers to prototype new features in an enterprise or for engineers to make internal tools, you might want to even have top-down sales. Yeah. Or at least be kind of product-led growth within businesses. Yeah. And maybe invest in like deep integrations into core business systems, other things like that. Totally. Whereas the consumer version, you might actually just want people to vibe code on mobile and get something that works in five minutes. And that's a great point too, which is like the consumer users often just want something to look cool and work and not have security issues. Whereas more business-oriented users, it often needs to integrate with what already exists for the business. Yeah. Whether that's like a design system and aesthetic or whether that's, you know, their CRM. Yeah. Or the emailing platform they use or sort of all of these different products that it needs to connect to that are external to the vibe coding tool. Yeah. And so I think the conclusion of the piece was like, we're seeing early winners in vibe coding already. Yeah. These are some of the fastest growing companies in the AI application space. Yeah. But we probably expect to see even more because it feels like we're so, so early. Totally. And many of the users of these products are probably still pretty technical. Yes. And so there'll be a version of vibe coding that's truly consumer-grade. Yes. That I'm personally very excited to unlock. And I think we've seen this in a lot of AI markets because these markets are large enough they can have multiple winners that are specialized. Like, we've seen this for LLMs. Yep. OpenAI, Anthropic, Google, Mistral. Like, there's XAI. There's all of these companies that have models that are really good at particular things. At different things, yeah. And we've also seen this a ton in image and video, which I think has a lot of corollaries to vibe coding, which is based on what type of user you are, what you care about, to what extent you need to reference an existing character, an existing design format, something like that. Do you want it on your phone and super fast? Yeah. Or do you want it in the browser and slower and the highest quality? Like, there are many companies that are doing super well focused on different segments or verticals of this giant market. Yeah. Super exciting. Well, thanks for joining us this week. If you've tried out any of these creative models or had any vibe coding experiments yourself, we'd love to hear from you. Please comment below and let us know. And also, please feel free to ping us here or on Twitter if you have ideas of what we should cover in a future episode. Thanks for listening to the A16Z podcast. If you enjoyed the episode, let us know by leaving a review at ratethispodcast.com slash A16Z. We've got more great conversations coming your way. See you next time. As a reminder, the content here is for informational purposes only. It should not be taken as legal business, tax, or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund. Please note that A16Z and its affiliates may also maintain investments in the companies discussed in this podcast. For more details, including a link to our investments, please see A16Z.com forward slash disclosures.


---

## 2025-08-13

### Alex Danco on Speechwriting, Blogging, and Giving Founders Power
**Publication Date:** 2025-08-13T04:29:53
**Episode ID:** 5077

**Full Transcript:**
What is the job of VC? The job of VC is literally you are the legitimacy bank, right? Your job is to make founders powerful. As you put in the work to write and as you put into work to read, what happens is actually reshapes your brain a little bit. It reshapes your understanding of what you're talking about such a way that the person writing can actually transfer some legitimacy to the person reading. There is something that is missing of the craft of like putting in an extraordinary amount of tortured effort into creating, you know, like a 5,000 word delivery of what is it that you have to say this year? Fresh off the news of his move from Shopify to join A16Z, Alex Danko joined TBPN to talk about the trade deal that brought him here and what he's setting out to do next. Alex shares why he's betting big on the craft of writing in an AI-saturated world, why speech writing might be venture's most underrated medium, and how great writing can serve as power transfer technology for founders. He reflects on his years at Shopify, his long-running career as a blogger, and why giving people the right words can change the directory of a pitch, a partnership, or a company. We'll hear about the formats he's most excited to explore at A16Z, the role of legitimacy in venture capital, and why sometimes the most important negotiation point is just getting unblocked on Twitter. Let's get into it. We have Alex Danko. We got a trade deal. Trade. The news broke today. He's going from Shopify to A16Z. Andreesen Horowitz. Eric Torenberg's latest pick up. There he is. Alex, welcome to the show. How you doing? Welcome to the show. Hey guys, thank you for having me on. Break it down for us. Anatomy of the deal, what they do. Did Mark Andreesen sit down with your mom? Did Mark Andreesen sit down with your parents? Tell them you got a bright future. We would like to take your son to the big leagues. I did have to have a phone call with Mark Andreesen right next to my mom because I was on vacation that week. We were seeing my parents. And the call with Mark was actually a stressful one because I had to give him my final negotiation demand, which was he had to unblock me on Twitter. No way. That's amazing. He's a notorious blocker and unblocker. What did you do to get blocked by the GOAT? So we don't know. We've decided not to look into it. Some things are best left as mystery in life. But we reserve the right to find out later. I've been blocked by people, had to apologize. I don't know exactly know why I got blocked, but you know, you always live to fight another day. His thumb could have slipped. Yeah, it's possible. So what's at the top of the to-do list today, this week, this month? What are you going to be doing for Andreesen Horowitz? So I'm coming on board. Eric brought me into this amazing group of people he is putting together, not to be understated and also not complete. There's more. Eric has more work to do yet. I'm coming on board. Job's not finished. Yeah, job's not finished. I'm coming on to help make all of the written content coming out of Andreesen be truly world class and as good as it can be. I think a lot of people on the internet know me from my writing online. I've been a blogger for a long time despite having done other things like be a founder. I've worked in VC before. I've been at Shopify for five years. But you know, most people I think know me just from, you know, writing and mouthing off on the internet and generally doing the craft that has been internet blogging, right? Which is just a really amazing and valuable part of tech that has been around for such a long time. You know, a really formative conversation in my career was, you know, once upon a time when I was a founder, my co-founder and I were trying to figure out how to launch a product. We didn't know what was involved in that or what that meant. And we went to a more experienced founder, our friend Amanda, and said, hey, you know, what do we do? How do we launch this product? And she said, oh, well, I think you should email your email list and say, hey, we're going to go and do this. Tell us what you like. Tell us where we should reach you. Tell us, get lots of feedback on all these things and then they'll help you out. And I said, wait, wait, wait, stop. What do you mean email your email list? What's an email list? She's like, oh, you don't have thousands of fans that adore you and wait for your every email every week. And I was like, I need to be someone with one of those. So ever since then, yeah, writing and newsletters and just the craft of having something to say has been a really important part of how I've always, you know, thought about how to be a great live player on the internet. How do you think about breaking through with text? Because the link ban on X is tough. AI is going to, yeah, yeah. Or is, like, should you just lean into more of the formats? I mean, there's certain amounts of like, you can just be built different, like Chris Pike, who just drops a link to a Google Doc and it always works somehow. People do screenshot essays, like, what's interesting? Something that stands out to me and why I'm excited to take this new role is I was having this thought yesterday. I was reading some particularly, like, sloppy AI generated text. And I was just, I was like, yes, the models are going to get better. But like, in a few years, like, at what point is, like, all the text that you're reading online and throughout your day just generated and there's no soul and craft put into it? And it's like, you can still, you can remove hyphens and delve and it's not this, it's you're not this, you're that, like, language. And you can still identify writing today. And I, and I just think, like, craft, like, the craft of writing and thinking clearly and coming up with, trying to come up with new ideas is super important. It's Lindy. Very Lindy. Yeah. So I like to think of it is that writing is power transfer technology, right? When you do it, it takes a lot of work to write something down and it takes work to read something, right? It takes more work to read something than to listen to it. But the important thing that happens is that as you put in the work to write and as you put into work to read, what happens is actually reshapes your brain a little bit. It reshapes your understanding of what you're talking about such a way that the person writing can actually transfer some legitimacy to the person reading, right? They can actually speak to this thing. They have words for something that they knew, but like, didn't quite know how to say before. And that gives them power, right? And it doesn't work the same way when you're talking, right? There is this fabulous complimentary kind of media called podcasts, which is listen for three hours and hear about all these great things. But to me, podcasts are an invitation to go find out something more. But if you actually want to do that power transfer right from the writer to the reader and give them something that gives them that power, like you got to write it down, right? And if you think about this for the job of a VC firm, right? It's like, what is the job of VC? The job of VC is literally you are the legitimacy bank, right? Your job is to make founders powerful, right? And having an amazing free tier of that by saying, we think a lot about these things. We want to give you words to express what you're trying to say so that a client, a hire, an investor will take you a little more seriously is really important to do. You know, so that's a big part of why we want to emphasize the goal is to give founders power. This is the job of the whole firm. And writing is just pretty good part of that. When I think about writing at A16Z, I think of a few buckets. There's a ton because the firm's written a lot for a long time. I think about, maybe it was like a decade ago, but I don't know how often it still happens. But the general partner who does the deal writes basically a deal memo and says, this is why we're investing in this company. And that's very interesting. There's also the Marc Andreessen op-ed in the Wall Street Journal, software is eating the world. It's time to build. These like big, like just like, you know, bombs on the timeline that drop and stick around for a long time. Then there's the market map, which is, it's been maligned, but I think it's deeply underrated. It's a time-honored tradition. It's a time-honored tradition. And I think these are in a unique position to actually put out great content there. And I've actually really enjoyed digging into those as we've been doing the show. And then there's also like the wildcard ones. Like I remember Andreessen used to do these interviews with the founders in the portfolio, just basically like, it's like, what's your everyday carry, but in the digital world? So it was like, what apps are you running? What tools are you using? Those are really cool. So there's a ton of stuff. And I probably mentioned, I missed like half of it, but maybe even more. But what's exciting to you? What's interesting? What kind of formats are you, do you see as like fertile ground to go explore if you've had the time to think about it so far? Yeah. So I'll tell you what I think is a really interesting meta that I'm going to spend a lot of time going after is speech writing. Okay. Um, speech writing is an interesting and kind of thrown by the wayside craft because now when you think about long form, it's like when you are interesting and you have something to say, you can go on a podcast, you can talk for a long time, or you are going to tweet about it. Right. But there is something that is missing of the craft of like putting in an extraordinary amount of tortured effort into creating, you know, like a 5,000 word delivery of what is it that you have to say this year? Right. And if you're a GP, right, it's like, Hey, you know, you get time and perspective to figure out like this year, what is the core thing that you want to say? Right. That is going to help inform all the other content, frankly, like people like Catherine at A16Z are also already incredible at this. Um, and bringing that sort of to more throughout the culture is going to be important either way, though. So you mentioned all these different types of speeches. I just, yes. Speech is incredibly underrated. We utilize, we utilize them internally with the team and, uh, and they're not every week. They're not on a schedule, but sometimes you, sometimes you need a speech, you know, just nail it and they can really set the tone and the energy within the company. And I'm getting chills thinking about Marc Andreessen standing on stage in front of thousands of people saying, we chose to raise this growth fund, not because it is easy, but because it is hard to test them, to test the ability of our LPs, to test the capital market, to measure them, to test the health of the global capital markets. There will never be enough venture capital. I mean, yeah, like a well, a well-defined phrase, uh, Andreessen has been fantastic, coinages. And I feel like, yeah, the speeches, that's an interesting answer. I was not expecting that, but that makes a ton of sense. Well, um, it's good to buy low on things. I think buying low, um, on speeches is your daily tip. That's great. That's great. Uh, where else should we go with this? I think, I think speeches could be an entirely new launch video meta, right? Everybody like the, the bar burners, uh, launch, everybody has a launch video. There's like three new launch videos every day. A lot of them like blur together because they're cool graphics and this person invested and, and here's this product UI. And if you just have the CEO just like rant at the camera and you can get people to like truly listen to that, it probably ends up being, um, you know, pretty, pretty powerful. Yep. Those kinds of things can go viral in really powerful ways, right? Because it tells people that you have something to say, right? And it's doubly important because you talked about all these different forms of writing that are all great in their own way. And the one thing that they all have in common is I'll tell you what all bloggers know, right? About writing is you have two audiences, right? The first audience is the people who actually read what you said, which is small. The second audience is the people that they tell that thing, right? Because they get something out of retelling it, right? Like they get that legitimacy, they get that ability to express themselves or whatever. And there is a trade between the writer and the inner circle of people who are going to actually listen to that speech or actually read that thing all the way through. And something that was great about the old VC blogging meta way back in the day, so 10, 12, 15 years ago when, you know, like AVC was cooking and Semmel, Shaw and Mark Schuster and people like that is the way a blog work, like the microstructure of blogging was you had a blog and you had readers and a comment section and everybody came to your blog and the readership would be there. And the way that you would tell what blogs were good was you would have lots of comments, right? And that's where your primary readership would then go and invisibly tell other people about it. Then the feed emerged, right? We got Twitter, we got Hacker News, we got places where suddenly the discussion moved in public. And what happened then is that first of all, the ability to reach a secondary audience exploded, so the returns to writing only got bigger, but it became less obvious to do, right? The trade became a little bit obscured by virtue of the fact that it's all in public, right? And it's all based on how many retweets and likes you get. And I think what's happening now as we go even further past this is that the returns to writing and reading have never been more valuable, but never been less obvious. So, you know, it's time to go. If you, if you go bring the output of a firm as legendary as A16Z with all the amazing things they have to say and the statements of record that they want to put out into the world, you know, my job is to go help Eric and the whole GP crew and Ben and Mark bring this back and make it amazing again, making it really like a brand that's going to shine. I can't wait for your first software is eating the world moment. Also. Yeah. I mean, I feel like the speech thing really ties into the new A16Z brand. Like when I see the coin, I feel like that's like the Art Deco coin with the abacus. Yeah. I feel like speech is kind of Art Deco in some ways. I don't know why I'm making that association, but it feels somewhat linked. Is it Art Deco or is it a Beaux-Arts, right? Like do you remember the line? It's like Art Deco is made by dwarves. Beaux-Arts is made by elves. Yeah. But it's very, it's very, uh, uh, what is it? Uh, it was like the style. It was Randian. And I feel like in, in, in Rand's writing, there's a lot of speeches that happen throughout the book. So there sure are famously. It makes sense. Yeah. Famous. Anyway, thank you so much for hopping on. Congratulations on the trade deal. Congratulations on the move and we're looking forward to seeing your work and hearing it. Thanks for having me on guys. Come on and give a speech soon. Absolutely. Speech. Speech. Speech. Speech. Speech. Speech. Thank you, Alex. Cheers. Thanks for listening to the A16Z podcast. If you enjoyed the episode, let us know by leaving a review at ratethispodcast.com slash A16Z. We've got more great conversations coming your way. See you next time. This information is for educational purposes only and is not a recommendation to buy, hold, or sell any investment or financial product. This podcast has been produced by a third party and may include paid promotional advertisements, other company references, and individuals unaffiliated with A16Z. Such advertisements, companies, and individuals are not endorsed by AH Capital Management LLC, A16Z, or any of its affiliates. Information is from sources deemed reliable on the date of publication, but A16Z does not guarantee its accuracy.


---

## 2025-08-11

### Steven Sinofsky & Balaji Srinivasan on the Future of AI, Tech, & the Global World Order
**Publication Date:** 2025-08-11T10:00:00
**Episode ID:** 5081

**Full Transcript:**
For four years, it was just a desert. The state blocked IPOs. They're blocking M&As. It was just an all-out anti-tech assault. D.C. is the zero-sum game. There's something positive out there, so it has to accrue to the D.C. power base. Figma managed to make its way through that, absolutely no thanks to the state attacking it. And then Lena Kahn decided to take a victory lap on this, which was, as I said, it's like the assassin congratulating themselves for helping to elect Trump. There's been a wave of M&A chaos lately. Meta and scale, Windsurf and Google, and a lot of it points to something bigger, how regulation, capital, and innovation are colliding in 2025. In today's episode, I brought on Steven Sinofsky and Vology Sreenivasan to break it all down. We get into how deal-making is changing from acquihires to what Vology calls aquifiers, plus the deeper power struggle between the state and the network, and what it all means for AI, startups, and the future of tech. Let's get into it. As a reminder, the content here is for informational purposes only, should not be taken as legal business, tax, or investment advice, or be used to evaluate any investment or security, and is not directed at any investors or potential investors in any A16Z fund. Please note that A16Z and its affiliates may also maintain investments in the companies discussed in this podcast. For more details, including a link to our investments, please see a16z.com forward slash disclosures. There's been a lot going on in the world of M&A in the last month, et cetera. There's been the meta large-scale, there's been the windsurf saga, there's been Gleana Khan discourse surrounding Figma, and I wanted to bring both Vology and Steven together to kind of reflect and discuss at a higher level how we make sense of what's happening in M&A land. And Vology, I know you've had some thoughts recently, so I thought I'd let you open. Yeah, so there's actually like three, I think, separate issues that are all kind of interrelated, and they're all kind of related to how U.S. capital markets are becoming tougher, but the interesting capital markets are opening up. Those are the windsurf, scale, character, and so on, this new kind of deal structure, then the Figma IPO, and then finally the new Genius Act. And to briefly summarize, since Starbucks, Sarbanes-Oxley in the early 2000s, which was passed in the wake of Enron, that was the intent was to stop Enrons, but it actually did stop IPOs. So the number of public companies has just declined, number of IPOs has declined, and tech companies started going private for longer. And then now with the FTC antitrust harassment of the last several years, that also started to cut off the M&A window. So for four years, it was just a desert, and DOJ went to interfere, for example, with JetBlue's acquisition of Spirit. Spirit went bust, Roblox had issues, a bunch of companies silently died. Go ahead. Roomba, Roomba, not Roblox. Go ahead. Yes, they said Roblox is fine. Sorry, Roomba, you're right. So first the state blocked IPOs, and so we had to go private for longer and build a whole PE kind of model. And then they're blocking M&As, and so essentially that just caused, I mean, among other things, there's also the assault on AI with limiting the number of flops, there's the assault on crypto with the SEC essentially doing lawfare against the whole space and debanking companies. It was just an all-out anti-tech assault. And then the amazing thing was Figma managed to make its way through that and actually get to IPO, absolutely no thanks to the state attacking it. And then Lena Kahn decided to take a victory lap on this, which was, as I said, it's like the assassin congratulating themselves for helping to elect Trump. It was quite a remarkable statement, but it really gets to the heart of sort of the way that DC is this zero-sum game. And so there's something positive out there, so it has to accrue to the DC power base because otherwise there's not enough positive left over. And so it was sort of this absorbing the one glimmer of hope that's out there and ignoring the long, long tail of carnage that they've recently caused. That's right, and basically the thing is they take credit for the good things, and the bad things, oh, well, that company must have sucked anyway or something like that, right? And actually, the DC thing, I'm not sure if this is apocryphal, but I remember I think Gates said something in the late 90s or early 2000s, actually before the whole antitrust thing, which you guys actually had to go through. You had to go through the whole thing. Something like he wanted nothing to do with Washington at all. He just wanted a code. And they said, well, that's fine. But some politician said, but we're just going to hold hearings on you, and then you're going to have to donate to us. Do you remember that? I remember somebody wrote that up. Go ahead. I think that there's just, I mean, part of what you said brought up two things for me. One is that, yeah, I mean, the whole thing about computing is that except for the IBM antitrust case, which started in the late 1960s and pretty much lasted through me in high school, the whole role, computing just kind of arose without government regulation, without government oversight, and even with the internet, with actual, with just government funding it. And so it's this very weird thing if you're in the business of governing and regulating that this giant thing that swallowed the economy happened without you. And also, to be fair, the entire software industry, in a sense, happened that way. You never needed to be licensed to be a software engineer. There was never approval to sell software. I mean, the most approval that the government got involved in was it used to prevent mail-order laptops and desktop computers because they had radios in them. And so they needed FCC approval in order to finally ship computers to home, which is something that a guy named Dana Lewin, who ran the Computer History Museum, he really cracked that working for Apple in the early 1980s. And that's how Macintosh made it to campuses, was that they figured out how to work around FCC. And then Michael Dell had to do the same thing in the PC world. So you had this whole industry that swallowed the economy, basically, happen without any hearings. I mean, there were just no hearings even. And so it's remarkable when you think about it. Yeah, so my framework on that, actually, and not that I use this for everything, but I think it's a useful framework, is network first state. And, like, the network, the internet, and the state, you know, the regulations and the government, and also informal things that are aligned with the state, because network's intangible, the scale of the internet and how quickly it grew is still something that even today, you know, Orwell had this saying, which is like, it takes an enormous effort to see what's in front of one's own face, right? And what's in front of one's own face? Well, it's a phone. It's a screen, right? The internet is simply the most popular thing in the world, perhaps in human history. It's completely ubiquitous. It's upstream of AI. It's upstream of phones, upstream of drones, upstream of everything on social media, and so on and so forth, upstream of the election. Twitter elected Trump, and then Twitter de-platformed Trump, and then X elected Trump. Like, the internet's, like, upstream of everything, and yet, because it's invisible, we don't think of it as a primary actor yet, you know, which is, I think, the whole other point. The other thing is, I think one of the most remarkable future historians in writing about this era will say something like, you need a license to cut hair, and you need a license to do this, and you need a license to do that. If you didn't need a license to own a computer, the most powerful device ever created. Right? Dang God, what an oversight. You know, you raise a really good point, and I, look, I'm not going to try to be the other side, but I can sort of defend that side, which is, it is true, you needed a license to apply makeup in a salon or give a massage, but, you know, not to write software to change the world, and I think it's so interesting to think about the mindset of the regulator, because, of course, all of the antitrust laws, if you go back, whether you start with the Sherman Act or the Clayton Act, they were based on these very tangible, distribution-constrained, resource-constrained world where, like, well, you can't own the railroad tracks, the railroad cars, and the coal that ships on all of them, because that's, like, this vertical integration thing, and, like, the PC industry just, it didn't have any of those constraints, and the computing industry, only for that brief time with IBM, where it cost tens of millions of dollars, and IBM actually chose to only lease them, not to sell them, which, of course, it makes a ton of sense in the world of technology, because owning a depreciating asset that doesn't matter in a year is actually a bad idea, and so, but all of those laws came about for that. I mean, even these crazy elements of it, like when they do merger and acquisition analysis, and they try to understand market share, which is not in the law. There's nowhere in the law that it says this, but they go, and they hire these people, and they compute, like, the HHI index, which is this way of, they take all the players in a market, so right away, you presume that the market is well-defined and has N players in it, and then they take each one's share, meaning you can actually measure it, and then they square the share and add those all up and divide by the number of players and decide if that's, like, greater than 0.25, less than 0.75, and then they go, oh, monopoly. This has been the challenge in computing forever. Like, even just take, like, what is the market for word processors? Is it, like, the thing called a word processor? Is it everywhere you can type? Is it only if you print it? And you very quickly can't figure out, like, what's the share of email? Is it the client? Is it the server? Does it depend on features? Is it mainframe-hosted, minicomputer-hosted, PC-hosted, or now cloud? And so all of these things, Steve Jobs put up a slide at the iPhone launch of mobile phone share, but he very deliberately chose to measure it by the manufacturer of phones so that it diminished the share of Windows phone. But he also could have just done it by operating system, which would have made a completely different chart. But what was the right way to define it? When Microsoft was going through Instante Trust, we had 100% share of the Windows market. Well, duh. And this is what you get into, like, when you look at a deal like, not even to pick up, but to pick robot vacuum cleaners. Do you count Optimus in the line, the share of robot vacuum cleaners, or is it only the spinning ones that cat sit on top of the dock in your living room corner? And they've always struggled with this, but they don't admit it. And so they apply this sort of econometrics to the whole thing that make it seem like it's this perfectly well-defined, well-reasoned thing. And even to this day, I don't think people, they would say it would be incorrect to define the phone market as iOS versus Android, because China would have something to say about that. Android itself, it's just not the same product across them. And do you count... Yeah, actually, I give three reactions to that, because I think there's a bunch of, I just want to shoot at that. Yeah, yeah. So the first is on, like, definition of market, it's actually Eric Schmidt's also talked to us, but basically, for example, when the iPhone came out, people didn't think of it as a competitor in terms of being a camera, but it was one of the most popular cameras because it was ubiquitous, and it was essentially zero incremental cost, and it was internet-connected, and it was programmable. And so even though the image quality is very poor, and the number of pixels was a little relative to a DLSR or whatever, it was a very popular camera. But it wasn't thought of as a camera as a primary axis. And often, the Christensen framework, you know, the late, great Clint Christensen, this whole disruptive innovation concept is something comes in, and it's not really recognizable as a peer to the existing products in the marketplace, but it's better on some critical axis, and it gains adoption in that way. And then eventually, it's a substitute. But it takes a while for people to even acknowledge it's coming in there. And then you also have a fuzzy set sort of thing where, for example, Google and Apple compete on operating systems, and Google and Facebook compete on ads, and Facebook and Apple compete on headsets, and so on and so forth. And so there's lots of fuzzy set, overlap kinds of things. And then another point is the entire concept of, oh, look at all the, Benny Devin said this good saying, which is, think about all the tech monopolies. There's so many of them. Ha ha, right? Yeah, yeah. Which is really, and the issue is they try to use these formulas as sometimes a substitute for judgment, and sometimes a mask for animus, right? Where really, you know, Elizabeth Warren was saying she wants to build an anti-crypto army, but really, she wanted to build an anti-tech army. And that's just like a particularly explicit thing where it's like, she's in a tribe that's against our tribe. And as you said, put yourself in their shoes. Like, first order, as people of the network versus them as people of the state. People of the state, it took me a while to understand them, but fundamentally what they want more than anything else is to get a piece of the state, to get a baton, to be able to be like, assemblyman of this, or undersecretary of that, to have a piece of the state, this baton, and they can allocate capital and start doing things for the good of the world and making you do this and forcing you to do that. And it's all about coercion, power over others, status, and the use of force implicitly or explicitly. Whereas our framework is the total opposite. We don't want anyone to have power over us. We're not asking to tell anybody what to do. We didn't consent to being in our organization. We just want a bare domain name like reddit.com, like a field that we can build up on ourselves and no one tells us what to do. Maybe an investment or something. Okay, maybe it's a board seat or something. But in general, you're just able to build on your own. And these two kinds of things can coexist for a long time so long as we're just typing and doing math and thereof regulating bombing countries or whatever it is. But as the network grew and grew and grew and got to tens of millions and hundreds of millions and eventually billions of people, we were like, this thing just grew to state level. And now these two things started conflict because we felt legitimately that we're the CEOs, the founders of these companies. We built them from scratch. We should be able to have authority on what happens on these networks. And these guys started to see, wait a second, their authority, whatever it is on paper, is actually being limited in practice because, for example, let's say you're a taxi and dining regulator. The actual regulator of taxis is Uber or Lyft because they have real-time tracking. They have star ratings on both sides. Or the FCC or something like that who issued licenses. Well, the actual regulator is Speech or what have you. It's then YouTube, Facebook. So our expansion, our peaceful, visible internet expansion started implicitly taking market share away from them and sends up regulatory power. So the empire struck back. They attacked us hard. And I can actually, if I squint, I can actually also understand how we would think like them and then vice versa, right? So how would they think they don't want others to have power over them? Well, they don't like the fact the network is getting so big it's able to dwarf them or whatever. How would we want to have power over something? Well, within our organizations, we want to be able to flip a switch and make something happen. And if there's a resistance to that, that's a huge pain and we want to be able to make that happen. We'll reorganize the company or something so that it can be better and more functional. There's another way of actually, have you guys ever seen the political compass? Yeah, yeah. Yeah. So it's the top left, authoritarian left, authoritarian right, libertarian left, libertarian right. And so if you roughly, roughly, roughly sit in the lower right corner, adjacents are often allied, but diagonals don't get along. So a libertarian right, I can sometimes understand the nationalists and I can understand the libertarian left, but the liberalist foreign quadrant doesn't really seem foreign to me until I ran a large tech platform. You know why? And of course you probably have. So, because Steve, you probably have this experience as well, but the libertarian right framework is everybody has consent and you pay them to do something and it's a market-based process and that works for many things. But let's say you're running a giant tech platform with hundreds of millions or even billions of people and you want to change some parameters. You cannot put that up for auction or discussion with everybody on everything, right? Instead, you're going to just flip a switch and they're all going to be basically opted into this and they're not going to get paid and they're just going to do, right? Because otherwise, there would literally be no way you could possibly have, like, you know, the complexity of these systems, every algorithm change, every update, every this, every that, cannot be something that's like, you know, you have five million parameter settings in any, you know, even Chrome, as complicated as it is, it sets like, you know, a zillion of those settings for defaults, right? So you have to pick defaults and for the most part, the platform will actually know better than the people because it's got all these analytics and so on and so forth. So you can put yourself into the Elizabeth Warren headspace if you think of yourself as a system administrator of a platform where you have lawful authority over it and you built it from scratch and so on and so forth. I think the difference then boils down to the competence law, right? See, the thing is, these platforms are at least competing with other platforms and if Apple or Microsoft or Google makes too bad a decision, then the people on those platforms have exit, they have choice, they can move between platforms so there's ultimately a market constraint. But the actual monopoly is at the DC level where there wasn't a practical switching option between things so they could just mess up the platform choice all the time and us being the apps on that platform, if you think of the state as a platform and companies as the apps on that platform, we would not have that much choice. Let me pause there, give you a thought. Well, I think that's a fantastic observation. I mean, one way to think about that is you, you know, and we probably won't even agree on some of this, but if you look at what the European Union has done with app stores, you actually see that dynamic playing out precisely, which is, you know, you have Apple who basically said, look, we want to build a platform that, we built PC platforms, we understand what it was like to build a Mac, we know how security violations happen, we know how privacy violations happen, we know how quality degrades over time due to software and third parties and apps, we know kernel mode versus user mode, we know all of this stuff. So when we built the iPhone and the platform for the iPhone, including the app store, we actually were like, we whiteboarded out and we deliberately said, well, we're going to constrain the API so that apps can't steal information from other apps, we're going to be secure and so we're not going to run a bunch of stuff in system mode, there's not going to be third party drivers, so there's no kernel mode, all these things. And then the European Union comes along after the success of that and then says, you know, good idea, but we actually want to return the phones to being PCs again. So now here's our Digital Markets Act, which basically says phones have to be back like PCs and Apple's like, time, time, you do understand, we literally set out to be more secure and to be private. You, the GDPR people, we actually wanted to solve this problem on the phone and we wanted to be secure and they're like, you know, you're right. So we're going to put in a thing that says, and vendors should be allowed to be secure. And you're like, well, what does that mean? And they're like, well, you have to actually go figure that out, but just know that as the regulators, we're demanding that you be as open and free as the PC and secure. And you're like, we did that once already. That is precisely what we went and did. And so you get in these kind of crazy loops and it's actually not unlike the loop that the media had with the internet, which was, you know, we believe in curation and editorial and control and own the distribution. And the internet's like, well, we have a way of doing distribution and we have a different view on curation and control. And then you get in these loops where then the media decide, well, we like the distribution that comes, but now we want to constrain the distribution. But we like the distribution, but we want to editorialize the distribution. And then the regulators come in and so that diagonal on the political compass is really just, I'm actually walking in your shoes right now and I realize what it is that you did, but I want to want that and I don't want to be tyranny of the or. I actually just want security and openness. I think a big part of it actually honestly boils down to the fact that they are simply not numerical and they're like AI agents. AI agents were helpful because they allowed me to model. I think all three of us are actually fairly verbal people. So we can write and so on and so forth. But we also have the system two thinking in Kahneman's phrase or what have you where you can just go heads down, you can program, you can do the math, the numbers actually have to add up. You have to do the spreadsheets, that has to be a numerical thing. And one of the things that I realized is a good chunk of the people who are in the American state, not the Chinese state, that's a different thing, we could talk about that. But the American state, a good chunk of them are those who are selected for having verbal and not numerical slash mathematical ability. As distinct from, let's say in the 50s or something like that where in the 50s because marginal tax rates were at 90% in America, they were at 100% in Soviet Russia, go to jail, do not pass code, do not collect $200 or 200 rubles. They're at 90% though in FDR's America. So there's a book by William White called The Organization Man where it was this extremely centralized environment, very corporate. You couldn't really found a company or anything like that. It was very hard for Shockley and Fairchild and so on to do what they did. But at that time the Elons of the world would have worked at NASA or run NASA and the Patrick Hollisons would have probably run the Federal Trade Commission and so on. And whatever was written down legally, they would just call each other and make it work. Right? You'd have a bunch of CEO-level people, founder-level people because they couldn't found companies that were channeled into the government to make it work. Similarly in the Soviet Union when those guys couldn't do entrepreneurship, they put all their energies in just pure math and science. And that's why there's some amazing Soviet mathematicians and physicists and so on if you're familiar with that because that was an area where okay, that kind of technical mindset could at least do something. Anyway, so because they're selected for this, one example of this, during the Cold War one example of this, you know, do you remember this Lorena Sanchez or Lorena Gonzalez who told Michael Solano that he was a billionaire? Right? Or how Bernie Sanders is like, a million is and a billion is. Right? Which is like seeing meters and kilometers. Right? Because actually it's like a thousand X difference. Or like, you know, when Brian Williams narrated the NYT editorial board said that like Bloomberg could give his fortune and divide it and give a million dollars to everybody. Right? So that's like three examples where I really start to think they think like billion means like big number. You know, like a primitive tribe will have numbers for like one, two, and many. Right? So like, they just don't understand like one E9, you know, like the difference between a billion and a million or the difference between for example, someone who has a billion dollars liquid, someone who has a billion dollars net worth, a billion dollar fund, a billion dollar valuation that leads to, like they literally can't, it's not like they can't do machine learning and they can't do gradient descent and they can't like divide or like, you know, and to have some sympathy for them, if I was to say what's the difference between a picofarad and a microfarad, right? Unless you've done something with hardware, you know, like what's a lot of capacitance and a little capacitance, like there's a scale there for capacitance or reductance or something like that that unless you're actually done electrical engineering, it's a microfarad. But they just have no intuition for scales of money beyond their personal experience, like a thousand bucks, beyond something that's in their bank account or checking account. They have no, they just don't know what's above that because they haven't run organizations or done investments. Like a billion might as well be a trillion, might as well be a quadrillion. Why don't we bubble it up a little bit and talk a little bit more about this M&A stuff because I just, I'm completely, I'm completely fascinated by, by, let's just take it in general, let's just take it as a stigma but just this, this kind of crazy revisionist thing that goes on with M&A. Like for me, like one of the big things is you have to just start from the premise that when a giant corporation does M&A, it's literally like a speculative investment that has- It's a power law but for M&A, exactly, I love that you said that. Right, that has a power law return. Like there's only two truisms about, about corporate M&A. One is, it literally, you, provably, a net destroyer of value. Like you, you, no matter how many studies get done at HBS or at MIT Sloan, I, I literally went and when I was teaching at HBS, I spent hours in the library and pulled all these, like papers with math and calculus and stuff in them that were against M&A because I found M&A at Microsoft very, very difficult to pull off because Bill was mandating this constant synergy and, and, and synchronicity across companies and synchronicity across products and M&A was like a huge perturbation to that whole system. Yeah. With the exception of like, something like PowerPoint which was the usual. Well, I'll get to PowerPoint because that's near and dear to me. But, but there, all the business literature on M&A is it's a destroyer of value. So you would think that the regulators would be out there against M&A not because of the success it has but because of the failure. Like they, they should be out there. The regulators should be saying, hey, you shouldn't buy companies because you just destroy them. But you never, ever hear them doing that and no company sets out to destroy it. And so I actually did in the Bosley, I actually brought my visual aid this time which we'll put up on the screen. Oh wow. Amazing. But this is, this is like what the New York Times, your favorite, NYT, what, what they said when Google acquired YouTube. And so the, the headline on the front page of the New York Times was like 500 words about copyright infringement and they're overpaid and it's just five guys and kitten videos and it's got like pull quotes from all these people explaining what a disaster it's going to be. So then you. All right, well I've got, I've got, I love that because I, can you put this one on the screen? So Instagram, you know, Instagram was something where at the time Jon Stewart said, because Instagram had no revenue they bought it. Little square pictures too, like retro square pictures with filters. Yeah, yeah, yeah, exactly. And, and, and Jon Stewart was like Instagram, the only thing that would be worth a billion dollars would be something that would instantly get me a gram of Coke, you know, or something like that, right? And, and so the thing is Instagram today is being retconned as this evil obvious move for the evil monopolist. At the time, Zuck was supposedly an idiot for doing it because Zuck offered a billion so double valuation. Second, that was about 25% of Facebook's $4 billion on cash in hand. Third, it was like weeks before the Facebook IPO. Fourth, the board wasn't consulted. Fifth, Instagram had no revenue. So the balls to do that when you're going into an IPO need to reassure the market that, oh, you know, this boy genius CEO needs, you know, all these idiots to say, oh, idle supervision is needed, blah, blah, blah, right? So, you know, the fact that Facebook is offering only a few weeks away spontaneous and improvisational business moves become more curious. You know, like, you know, or Hacker News, this is not going to be one of the best tech acquisitions of the next decade. Instagram is a photo service in a sea of other photo services. Can someone please tell me how Instagram's actual content is worth anything? Seems like mostly a huge waste of cash. And then Alex, a market cap of $950 million The New York Times is worth, quote, less than Instagram. True. True. Yeah. Yeah. Yeah. I'll give that. That's true. But yeah, but I think it's also like you have to actually read the reasons why people thought, because the reasons end up being these very pedestrian sort of non-math, unable to see exponential growth, like not strategic. They just, they always fall back on something like, in fact, you know, Instagram was on revenue. YouTube had no revenue, but also it was like this morass of copyright violations. And how will Google ever be able to make a profit out of that? And, you know, there's a lot of questions and how will Google ever figure that out? And no one ever wrote about the potential. And of course, the potential. Yeah. And go ahead. So the potential is the part that it's the venture bet that the company is making. And the interesting thing is big companies make the wrong potential that 90% of the time, like they generally always think, you know, like they'll do like a HP autonomy acquisition was a very famous off, went off the rails acquisition. Yeah. Yeah. Yeah. Yeah. During the enterprise software world where HP just thought, well, this is sort of this nth tier player in enterprise search and information retrieval, but we'll buy them and we'll put our magical sales force and platform strength behind it. And that will fix everything, which is like 90% of the M and A that happens. The big company just assumes that whatever it's strong at, it will just wave that dust over this failing business and it will make it great. And I think, yes, that's right. And I think that that's what it's always like this venture aspect of it that's missing in this retcon that, that they should have stopped it or that they should go back and stop it because it got made into a success against all of the conventional wisdom at the time. It, it just completely blows my mind that that's the framework for, for evaluating an M and A that, that people would, would use. I mean, you know, you can retroactively consider whether, you know, Roomba really would have been better off being bought by Amazon even though it should have been. You know what it is? You know what it is? Everybody wants a piece of the reward. No one wants a piece of the risk. Right? So, the, when the state goes and blocks these acquisitions, they, they assume no downside risk. They're, they're not like taking, you know, hey, like, like for example, Adobe had to pay a billion a fig month for the breakup. Right? Like the breakup fee that the startup team got through. So, it just goes in metals and then these people at the hot spot would take a victory lap, you know, as really just, you know, you know, Stolen Banner, Valor? It's like Stolina Valor. Right? Lena Kahn, Stolen Valor, right? And, genuinely, like, Dylan Field, like, and the Figma team, superhero this, but just to talk about that for a second, like with an M and A, you made a bunch of good points, and the best M and A you do can completely transform your company. A lot of the returns essentially fail and sometimes it's a little bit unpredictable. Number two, I think is, in general, a company usually needs, in my view, and you may disagree, you need to be about a hundred exercise of the small company in order to acquire them. And the reason is, if it's even only 10 exercise, I've only thought, I can only think about one deal where it was about 10 exercise and it worked and that was Illumina's acquisition of Selexa, where it's like a must win, that's in the genome sequencing space, but that, or gene sequencing space, that's where there was like a really important technology that became like the basis for everything Illumina did for the next decade and the entire executive team was bought in on it because 10% of your cap table, 10% of your equity is like a huge amount. It's basically more than you're going to spend for the whole year, maybe for multiple years at a time. And so, a 10% bite is massive. It has to really be 1% and that's still a whole integration effort. That's number two and the reason I say this, lots of founders at various stages will be like, oh, I'm acquiring another startup and I'm like, startup deals never work in general because neither of them have money. Maybe one of them can shut down and join the other one. That sometimes works once in a while, but in general, they don't work. That's why M doesn't work, but A works. Like merger usually doesn't work, but acquisition works. Well, AOL and Time Warner and stuff, what a huge disaster that was. Yeah, exactly. Again, it's a sea of jobs, Pixar, and all the ones that work are sui generis where it's like they really acquired some amazing founder as part of that and then leads a company or something. The third thing about M and A, as you again said, is that the smart big company values them on the basis of the big company's distribution, right? And it's this product times that distribution is something. However, the dumb big company just thinks they can just roll up anything and sell it and that just doesn't work, right? I think one of the huge I mean, the responses, by the way, on this Figma thing and then let's get to actually Windsurf, I want to talk about that as well and then also the Genius Act. The response on the Figma thing I think fell into one of three categories. The first was the Elizabeth Warren school, which is just anti-crypto army, anti-tech army, they hate tech guys, and I actually like that because that's just like pure tribal animus. Okay, you bring your war paint on the 50 yard line, you bring your guys, we bring our guys, let's, you know, win the battle for the idea, let's go, right? I actually prefer that because that's like explicit conflict and it's just, you know, tribe versus tribe, you know, got the war paint on. Okay. Then you've got the like, well-meaning maybe, but, you know, I often can't tell if they're trying to kill us or they're just actually arsonists or what have you, right? Which is, oh, if we allow startups, if we allow them to become big and not be eaten by these other, you know, companies or what have you, and I struggle for the analogy or what have you, but it's like, I don't know, you can't hire somebody until you interview 20 people because then they'll be like the best of 20 people and we're going to let you hire the best of 20 people. What it does is, first of all, you know, you shouldn't be interfering with that choice. Second is, that if you cut off the flow of M&As, obviously, most companies aren't, you know, either good enough or it's really tough to make it all the way to IPO. Like, Oculus, for example, down 10 years ago, they were burning a lot of cash. They probably couldn't have made it to IPO. A lot of companies are like that. They're burning cash where they're valuable to a big, deep-pocketed acquirer and there's like maybe one or five guys who could buy them, 10 guys, 20 guys, whatever the number is, but they really can't operate as a standalone company. So, in that circumstance, you know, airlines are often like this where there's a ton of fixed costs that go into it and, you know, like mergers make sense because they have routes and stuff like that, the JetBlue Spirit one, right? So, when they block those deals, they are actually destroying value, right? And, moreover, one of the biggest issues in this related regulation in general is, they think of it as, oh, this is punishing the big tech companies, the punishing of the companies. So, they think of it as a punitive measure because if the big companies can't buy, well, well, first of all, figure out other things because we'll get to these complex deal structures, but second is, that means less money for startups because when a big company makes a big acquisition, that's a big surrender because it means a big company couldn't have built it themselves. Like, Google had Google Video but it had to buy YouTube for 1.6 bill which certainly caused, I'm sure, some churning internally by the Google Video guys, like, we could build it ourselves or, no, no, we're paying too much or something like that. So, it's often a surrender for a big company to do this. It's not what they wanted to do. They didn't want to pay a billion dollars or whatever for this and then that surrender money, it goes and excites everybody. They're like, let's make a million Instagrams when you see a big billion dollars for an Instagram acquisition and then you get Snapchat and then you get TikTok and you get all these other competitors. So, Facebook, it's like throwing fertilizer on, you know, the actual way of regulating big companies is with a thousand startup piranhas, not by dysregulation. Let me pause here because we want to... No, that's a fantastic observation because you always remember that in a big company, whenever something new that's adjacent pops up, the immediate reaction is, okay, we're selling this giant blob of stuff in software. We're selling this giant blob of software and this thing is adjacent to it. So, our blob needs to have that thing and that's what immediately gets the antitrust regulators, oh, but that's expansion by leverage or by tying or something like that. Tying? Oh my God. What does tying mean? Tying means you're tying peanut butter and jelly together in a sandwich. Tying is like business strategy 101. Now, 10 years later, the truth can be told and I'll tell you. Right. And so, you have all these meetings at a big company which is, well, should we make it or should we buy it? And it's just a question that you're going to have. And of course, this is the funny part about Big companies find it hard to make though, but go ahead. But this is the funny thing because, you know, if the regulators get involved, then they get all the memos and all the emails and it turns out inside the company, half the people said we could make it and half the people said we could buy it and all the people said we have to have this thing and they said it with varying levels of hysteria and like, it's like, we have to have this, this is going to put us out of business and we're going to be on the peripheral asking for it. So, which one of those enters the discovery for the regulators? The hysterical person who's probably the person on point losing a deal in sales or the engineer that just is mesmerized by the exciting implementation of something. And, and like, that's exactly what, that's the, but then they still go back and have the make versus buy. They always make one of two choices. They, they almost never really just try to make it. Unless they have to because the one that they want, there's only one, they can't buy it or whatever. They, they, it's very, very hard to succeed on the make versus buy when you go to choose make. So then you go buy and they, there's a fork in the road. About two thirds of the time the big company says, wow, the leader is really expensive but we have our magic distribution beans so we're going to, we're going to pick the number two or number three that's like way, way cheaper and get in a fire sale and of course, it never works. Like Microsoft, When does that ever, when does that ever work? I'm actually trying to think. It doesn't. But like you could, you have Google bought Motorola. I had double click, Google bought double click and then what is it? AQuantive. Microsoft bought AQuantive for $5 billion. You had Sprint merging with Nextel which was like two number fours if that was a possibility. You have Microsoft and Nokia. I made a giant long list. You had everybody in the phone business that needed, already in the chip business that needed modems and so then they went and everybody bought these like number two or three modem makers. Like NVIDIA almost got overtaken by a PE Raider because it bought a modem company and that was a signal to the market that it was completely confused about gaming graphics. What do you have to, why would you compete with Qualcomm from a gaming graphics company? And this just goes on and on and on with that kind of thing but then you still get to the point where you want to buy something which is still a power law return which is still a power law return which is still a power law return which is still a power law return but again one of the things that doesn't get taken into account is that in a venture investments or acquisitions from a company can actually be really transformative to the big company which is a thing that the regulators don't really see because they see the world as a static fixed pie. So they think like once a company is like IBM and owns mainframes or is Microsoft and owns Windows well that's just what it should do. It should then just take Windows forever and just be the Windows company. This is where tech people are very very different because they just assume tech has this finite you know sell by date and that the tech is just not going to be all that useful down the road so you know you have to reinvent yourself and you know like it's not like people in you know 1985 thought Apple was going to be a phone company and like that that whole mindset it just sort of escapes people. Like here's an example that was hugely transformative for Microsoft that nobody knows about today which was in the throws of the rise of the internet in 1996 or so we bought a company called Frontpage which was basically a word processor for the web and it was a way to design a whole website and to also do something that nobody else did which was you could edit on a PC push a button and those things would end up working and at the time it was actually pretty good. It was super cool but what it did to Microsoft was it like I was in office we did the deal but we had a fight with the Internet Explorer team who thought they should do the deal but they didn't want to do the deal until they saw us wanting to do the deal which is a whole how things work in a big company and so we ended up first we had to solve the bidding war within our company and then we had to get on the phone with Mark but the thing that it did was it galvanized Microsoft to say you know what's really important on the Internet is editing and nobody was really solving the way to edit this very finite thing called HTML and publish it to an Apache web server and so we finally figured out that like editing on the Internet was not going to be like Word and it was going to be a different kind of tool that involved script that involved programming and that's what led to a series of things and the people we brought in were experts in the Internet and editing on the Internet which we just didn't have and although the product never materialized as a big Microsoft thing the people infused that DNA into the company that enabled Microsoft to go and figure out how to do editing in a browser which turned out to be incredibly important and that kind of thing is transformative but it also transformed the whole industry like where would you get these dynamic websites and the way you could edit web in the browser and stuff like that wouldn't have happened because we were just not innovating there and I feel like that whole thing is missing even from the Figma which again the specifics of Figma aren't really super important but it was a whole new innovative category of how to do tooling which then gets to AI and tooling so I think in general one of the things that's been happening is due to the not just past people can only remember maybe a name it's like a fleeting kind of thing they're like well Linicoln is gone so therefore nothing has changed US first Google is a giant interest is still going FTC first meta is still going all the antitrust stuff is also not just the US all these other countries that ganged up on the Figma thing there's just antitrust situation so because of that a lot of the big companies have been forced to innovate on deal structures and do things that are new scale character inflection adapt covariant are all similar where essentially they're not all the same but there's a typical acquisition where you have an acquired let's call it Google shares and there's a process which most people watching the show will know but if they don't there's something called the capitalization table which says who owns what shares and there's something associated with it called liquidation waterfall that says who gets what money when and so for example if there's debt providers how they get paid that's the whole thing okay then you've got something which is like an aqua hire and aqua hire is something where I'm just describing these basic things just to set the context for what this sort of thing was so an aqua hire is something where the acquired company doesn't really get any money it's not usually done through the liquidation waterfall instead the company just shuts down but there's a press release or some cash that's given to the investors but essentially it's way better to at least get an aqua hire than to have a total go to zero moment because you get the status it's not the money right that's what I was thinking about it right and now we get to the third thing which is what these sales structures have where they have an aqua hire component but they also have scale character inflection adept covariant and windsurf the big company basically bought the top AI researchers and engineers out of the smaller company and paid a huge sum for that but then it wasn't actually buying the company the company was left as a shell or as actually an existing entity and then let's say for example the case of windsurf you had 40 people go to google and about there was a huge chunk of money that was left in the bank account of the left behind entity and it's usually set up and it was in the case of windsurf in such a way that the money that was left in the company is what they would have received through the liquidation waterfall right and so the point is that an aqua hire you get the status but not the money in an aqua fire you get the money but not the status okay so that you know you seen the dark man you know bane he's like we need one of us to be in the wreckage brother right so whoever was in the left behind you know company right was on was somebody who is well behaved enough to basically like okay salute i'm going to go kind of down with the vehicle i'm going to dividend the money out you know deal with it silently and so on and so forth right it was uh you know you know get the president like i think it's like the speaker of the house blah blah and you get to like number 37 it's like the secretary of interior or something like that keeper sutherland the housing and urban development right right exactly right so the keeper sutherland is the designated successor if the entire leadership structure is decapitated or in this case acquired right if they're all raptured right that that is the person who's behind is now is we need to have you know what comes to the key man provision yeah we have a non key man provision which is this is the designated executive who is in the event of an aquifer like thing and we can decide how to describe it it's not an acquisition because there's an acquisition then you have all the fdc blah blah blah blah blah stuff right but in the event of an aquifer this non key man stays behind he gets maybe a little more money than he wore a lot more money whatever because he's not getting the status of being acquired okay but he executes an orderly shutdown of the company doesn't have any drama yeah and just dividends out the money okay the issue is that this deal structure was new enough that the other five times it went fairly well but in this context what didn't happen and just to give you some details that I'm aware of first most of the windsurf employees are just being hired in the last few months because they were left behind and Google when acquiring the company didn't want to acquire the sales guys to Google has its own sales team Google just one of the engineers right third Google put a hundred million plus in the bank account of windsurf where the intent was to dividend it out but the guys who are left behind didn't understand what's happening because their sales guys they're just think about money or whatever and the problem is it was it was so constrained in terms of what could be said about what's going on since it's so constrained in terms of what could be said about what's going on since they couldn't say anything about what was actually happening the people who are doing the deal couldn't communicate clearly about what was happening so just look like oh my god the founders left and they left everybody in the lurch oh they broke the social contract and so that's not actually what happened at all what happened was the FTC and others had made acquisitions so difficult that they had to do this other structure and that's one interpretation the other interpretation is the people left behind got money but not status so after all if you put yourselves in their position like normally in an acquisition Google might have acquired a 250 person company and they might have kept 40 people and the other 200 people they said hey we're not acquiring but but but but those people would have had a face-saving thing and they would have had a line on their CV saying my company was bought by Google you know I decided to do something else afterwards and you know it has to be both parties have to agree both the big company and small guy you know have to agree hey I want to still work at Google rather than do another startup it's very common everybody has a broad warm halo your exact exit number isn't published online you know whether you've got an offer letter isn't published online so everybody who is acquired has a junction point where they can choose to go the big company or not and they have the status and the money right so the issue with the FTC interference in that is it broke the status part of the transaction where the FTC interference so but they did have money so what do they do rationally for them they negotiate a second acquisition with Cognition where they got the status of being acquired now the issue is Cognition is like 60 people and the acquiring the 200 people of Windsurf that gets back to our earlier point usually a company can't buy something that it's not 10x greater than so it'll be very challenging for Cognition I think you know I have nothing against Cognition nothing against Windsurf nothing against any of the people here I wish everybody the best Cognition is Windsurf is awesome Varun is awesome I have nothing nothing bad to say about anybody just describing the incentives right so Cognition will find it challenging I think to integrate those 200 people and I'll be also challenging for them to lay anybody off because they you know said oh we we brought everybody on I think on the on the Windsurf side basically like Varun side he's muzzled so he can't say anything and in general my view is usually the guy who's getting pummeled on social media and can't speak is usually not as bad a guy as it's made out to be he just literally can't defend himself right but but to defend him it's this deal is essentially the same as the other five deals the difference is the people left behind you know didn't want to play the key for Southerland role or what have you just because you know for our reason which is which is their prerogative the way we solve in the future is a non key man clause and there's somebody who's maybe paid more to shut down the company turn off the lights because I grant that that sucks and I understand why their egos were wounded and so on and so forth but ultimately the person to blame one of the other things that happens here isn't something like this the last person with a face is the one who's blamed right because Varun has a face but Google doesn't and the FTC doesn't and then the general anti-tech antitrust US first Google FTC first meta kind of stuff doesn't right so last guy with a face is blamed but the faceless stuff isn't you know it's almost like Baschiat seen and unseen right but blame the FTC blame the con and and there's one thing which is someone asked well why isn't the current administration reversing this and the answer is the current administration for totally different reasons I think they have a legitimate bone to pick with big tech because of the censorship and so on and so forth but as a consequence of that many of the cases that were started have been continued right so it's not like this thing's just completely went away the new administration is friendly to little tech mostly but unfriendly to big tech and continuing those cases and then this is the big tech interaction effect that's going on there all right that's a lot I just said let me pause there's more I can say well those those are super I mean very tough stories to hear and I two things really jump out of me one is just purely on the shaping of the landscape and what's going on I think these are extremely important let's just call them deals and the reason they're extremely important deals is because the way are we're I would say with near certainty or in general I would say with near certainty or in general I would say with near certainty or in general but for me personally we're undergoing a platform shift now with with AI we don't know I can't say who the winner is I don't want to say it's not really important but there is a shift in where the nexus of the broad tech ecosystem energy is going to be from mobile and cloud to AI now whether or not that's a complete break or the same players move to that transition don't know but but that what that means is first and foremost the most exciting things that are going to be going on in the near term are in the tooling to enable the platform and and that's especially true because the way that the AI and platform shift is happening is there's just a lot of players and there's a lot of people and it reminds me a great deal of the consolidation of the PC operating system world which was there were dozens of PC operating systems in in 1980 and when IBM came out with the PC and Microsoft came out with DOS part of the consolidation was due to the implementation of the basic programming language that had already gained strength across many of the platforms but this consolidation that on boot up there was basic and then this proliferation of tooling that appeared on DOS because Microsoft invested irrationally in tooling IBM invested irrationally in tooling far more than there were any independent tool makers and I think what's happening in AI right now when you look at all of the energy around coding is that this is really building the tooling for the AI era and and so it's going to be an irrational investment because tooling itself is never a really huge business because you have to have it and so it's sort of this well if you have to have it then there's going to be there are going to be many alternatives and they're going to be some low price ones some high price ones but the people that want to have the predominant platform will invest irrationally in tooling and so that's why you're getting these deals that don't look rational because there there's just a bunch of tooling the the second thing is it's really important to put this in perspective if you're one of those people who think that this is kind of gross or hacking the rules in some way which is antitrust law was itself designed if you go back to the Sherman Act it was this very vague it was barely three pages of legislation and it was really designed to attack one specific thing and the word trust in that context just meant contract and so what was happening is between the railroads and manufacturing and resources and stuff the the way that interstate commerce happened a company in one geography would sign a contract with a company a provider or a vertical partner in another geography and there were the interstate commerce laws had not yet really been established and so it was sort of this free for all of like these exclusive contracts by geography by resource type by train tracks and it was locking out whole parts of the country from from the availability of those things so so this antitrust became break up these vertically integrated or these horizontally constrained entities and then when the Clayton Antitrust Act came along it said oh you know the real problem is pricing and tying and so then all the laws became about how much you can charge can you have exclusive deals not exclusive deals and in each step well you know the first time well then Delaware came along and started being really favorable to companies that were doing business in multiple states and so you ended up with this sort of and I'm I don't want to get criticized by by legal historians or business historians or whatever like I'm I'm not paying fast and loose I'm trying to be abstract about what took place over 30 years but then you know then when pricing came along what businesses just started to develop all of these different ways of doing the pricing like like one of the most common things people know is like if you buy a lot of something you get a better price but if you actually read the Clayton Act like that doesn't appear to be legal and so then it took a whole bunch of court cases to just make this very basic premise which is the more you buy the better price you get because I like good customers or if you commit to not buying my competitors products will give you a good price and the Clayton Act was like you cannot do that and you're like but that seems to be a fairly reasonable constraint like you're not going to buy it for me and play that off my competitor and I'll be nice to you and so all of these things and so at each juncture in the evolution of regulatory oversight like the next step of it was what could be viewed as a hack to the systems that got put in place which generates this animosity with regulators and of course you go back banking is a classic one where like checking accounts didn't have interest and so someone clever with software invented this notion that you have a checking account and a savings account and your savings account has all your money in it and the minute you write a check we move money from your savings account to your checking account so it stops earning interest we pay the check and you're covered and that was called a now account and that innovation allowed you to have interest on a checking account which turned out to be a really a really big thing when MCI came out with like we want you to use our deregulated long distance but we want you to you like only get a really good price when you call 10 friends and family will give you a really good price so everybody around the country signed up for MCI when phones were deregulated and had to make a list of all of their friends which of course turned out to be this massively great marketing tool because then they would take that list you gave them give you a discount for calling those 10 people and then hit those 10 people up to be part of friends and family but that was just like a software innovation that completely worked around this idea that the price of long distance should be the same for everyone everywhere and then AT&T did it with three minutes up to unlimited long distance calling and so what's happening now is just like okay the regulations have been fixed for a long time we want to invest irrationally in platforms you're making this part of it very difficult so we're just going to go figure out an innovative way and so we have to be careful because of course they are going to circle back and make this difficult in some way and that's the cycle that you you get in with with regulatory oversight oversight and you know you could be like I've always the guy I used to stand up and fight about like this feels like the guy in basketball who decided that when there's seven seconds left you should intentionally foul someone I always thought that is like the most unsportsmanlike thing because I'm like they didn't invent fouls to like be executed on purpose they did it so you wouldn't poke the other guy's eyes out but it became part of the strategy and that is like the ultimate American capitalism is exploiting the rules that way and there you well so and it's also Silicon Valley it's also Silicon Valley yeah yeah so I think that what happens is the following is that you start out in a totally honorable I think fairly honorable you know capitalistic way and then what happens is when the government attached you enough then sometimes the companies that survived that get a taste for the one rank yeah yeah right and they're like okay well you know what we just built this huge lobbying team to defend ourselves what if we go on offense right and they're kind of corrupted by it in a certain way and the one issue there's like I think you know in chemistry if you think about like reaction kinetics sometimes you can have a bunch of time constants where you have this reaction this reaction this reaction they're all going and you have to actually do the math figure out which one goes first you know and so I think there's several hitting at the same time in this space that I'll just give them a quick succession the first is these big companies are now getting the taste they're forced to they wouldn't actually want to consider this in the first place but of you know getting like rather than buying the cow they're getting the milk for free right decapitation rather than acquisition right now they know that that's a thing actually it's faster than an acquisition just leave the money in the car you know it's like it's almost like a deal you're just buying something from somebody it's closer just like a big big purchase order almost than it is to an acquisition with all the complexities that are involved in that so now they're like oh I can do that faster and less overhead let me have five of those right yeah so that's that's like that's like one thing that's happening where you're giving big companies now a taste of this and it's like you know so we'll have to figure out our deal terms to account for that as something that counts as a as an exit but doesn't count as an exit you know we'll figure it out okay the second thing is um AI is making it so that you can do more with less more with fewer people right so this will be a more common thing where there's an internal um you know amplified intelligence rather than artificial intelligence you're going to have a stratification within every company in between companies where the top people will become more and more and more valuable because they can just do do so much more so much more quickly right um and the third thing is you know one thing people say about AI that I actually don't agree with didn't agree with then and actually I don't agree with now is this is the worst you'll ever be you know that this that was used to say right but I remember with Napster Napster was actually the best it was and then the all the copyright lawsuits and attacks and it made it worse and worse over time google books books was amazing and then all these copyright lawsuits gelded it enough so that you could get like some little snippet preview and then you couldn't see the whole thing right and so it's quite possible I would even say probable that the combination of all the copyright lawsuits these are desperate lawsuits by the way desperate attacks by all these journalists and you know authors writers etc who hate AI and I understand why they hate it but they just hate it so they just want to kill the thing and you know they'll say it they'll say are you an AI supporter with like venom in their voice it's like have you not heard that I yeah good I'll follow up I promise I will let you just get away with that okay okay yes it's like because like you know they'd say like are you a Trump supporter are you an AI supporter you know and and some there was some company there's a few that it's similar to actually like when discord tried to roll out crypto like you're doing crypto you know people got super super mad right and that is a building thing of an anti-anti crypto anti tech and it's setting fire to the way most it's a real thing that we should not just watch out for I think it's going to become actually the future political axis between futurism and primitivism that's going to be the new left right after the whole thing finishes rotating but so the issue is that those attacks from a copyright standpoint and also the energy constraints because data center build outs are going to just start hitting you know spare energy constraints and the fact the Chinese models are open and they're actually pretty good and they're distributing them quickly and China's do you see my post on AI production a few months ago right that's happening now you've got Kimmy you've got Quinn you've got deep seek these are good models and they're open I shouldn't say fully open sources are open coefficients but not open source because the they haven't released the full source code to build them and all the complexity that involves and so and so forth but are open coefficients and so the combination of those three things means it's quite possible and then the fourth is you know I already saw something where some you know government restriction on using hosted deep seek okay I can understand that hosted deep seek is going to China but I wouldn't be surprised to see something where it all combines such that a US AI companies are hit with copyright lawsuits B they're blocked by the lack of energy C the Chinese open models are out there and D US regulations prohibit people from using the Chinese open models so that actually that lead in AI is actually lost and becomes harder to do AI in the US and it's similar to what happened with crypto where crypto had to decentralize outside the US in the 2020 24 24 range I don't think that's the intent but I can see those storm clouds coming and the one other thing I'd say is because AI doesn't middle to middle not intend it doesn't do everything but it does do a lot of there's a lot of you know bureaucratic jobs you know jobs that lawyers do that doctors do the teachers do professors artists journalists this is going after like the blue base really going after them and and so you know doing all this AI in San Francisco and publicly making millions or even billions of dollars and being demographically different with all these immigrants and being very publicly rich and recognizable in the blue state in the blue city in the blue city in the union to me is not a good long-term recipe for peace and prosperity right it results in accumulating too much capital to publicly and then you just start to see some very very nasty things happening so so because of all that I think I am bullish on decentralize AI but I'm not so sure how centralized American AI is going to I think this is a good way to close I'm going to I'm going to do the impossible thing with with ebology which is I'm going to try to get the last word in and let Eric just say thank you very much. We opened up a lot of topics and I I would encourage comments and dialogue on X for where we should take the next part of this because we should keep going but but like I want to say broadly and deeply I agree on the the biggest issue we all face right now in in the technology sector of the economy is the risk to to the AI innovation trajectory in the US like and you can look at that from a technology perspective a regulatory perspective a business practices perspective an immigration perspective like a research funding any way you want to look at it there are arrows aimed at from various perspectives from from preventing it when the right answer is we need we just need to let the market work the market for talent the market for technology the market for people there's there's just a very strong market that can can really really work because from the Clay Christensen perspective what China is trying to do is commoditizing our strength and so the the release of a bunch of opens pure open source open weight models coming from China is specifically designed to go after a rigid or complacent American view of AI which is you know cloud hosted by a few big players you know closed source you know that that so China is just doing and I can look at this very emotionally and personally which is this is Google releasing Google Docs for free yeah yeah yeah exactly and I'm running Microsoft office and Google is just like we're never going to make money from this and here we are to twenty twenty five they still don't make any money from it but they do they and what Microsoft that up relying on is the worst part of the business which is just enterprise distribution lock-in as your core part of your business not innovation not moving forward which bums me out I mean they make money from G Suite the host of G Suite is starting to get expensive so they are expensive but relative to what you guys are me it's like it's like the profits from office are still the profits of Microsoft with Windows and stuff but the other angle is like copyright I'm going to come at it from a different angle and we should maybe think about talking about this because I I think people are the people are rightfully panicked about the US position and then point to one of those slings and arrows being copyright which of course has no issue in China at all like they have no problem with copyrights you know ask the pharma industry I lived in China I worked on copyright I know exactly what they're doing but but the truth is is that copyright also created the technology industry at my in the world and it was Microsoft and Intel with intellectual property and copyright that that and Apple that enable the industry and so we have to look at it a little bit more critically and not think of just about the you know the starving novelist in in Brooklyn who is frustrated by being used as training data there's there's a lot more totally there's a lot more of course of course there's a lot of depth to the to the copyright issue and finally I I do think that there is a to wrap up just the M&A side that the recent wave of deals is going to get looked at with scrutiny and and the truth is is that something will change in what's permitted in in deal structures in terms of oversight because I think they're too big to get ignored by regulators in a tech industry that they're no longer just going to ignore but I also think that there's a lot of opportunity to to be have much more clarity in deal structure to maybe it's a great idea from apology raise like to have you know designated survivors as part of corporate governance I mean there's a lot of interesting things you can think of to make that kind of outcome something that's thought about because of course today you know people who take on money from very late stage private equity investors or corporate venture they know the terms and conditions that you have to have in those deals to attract that money and so in the same way if you know the kinds of things that might happen you structure your cap table you structure your corporate governance to facilitate that or prevent it and right now and then it becomes part of the business practice and then it becomes formalized and it's less likely to be something that could just be stopped by sort of an arbitrary ruling by an appellate court in the 8th district who doesn't like a deal that happened to a local company you know which I think is where we end up with the risk right now is that you'll will just it'll be arbitrary and nothing is worse for anybody that than arbitrary but I feel like we have this very long arc of discussion that was super interesting in terms of M&A and where we're heading and look to where to pick it up. Great. If Lena Khan a few years ago when she was sort of you know if she was asking for advice or perspective is your view hey let the markets work because M&A helps you know everybody from big companies to small companies to take your system to the consumer or how should we think about antitrust? Well I'll go first and then but we should wrap up on biology for sure which is just the truth is because M&A will almost certainly fail unless they want to come out on on the regulatory side of like defending against the potential for failure they they really can't come out on the we predict that this one will be successful because that that just it's statistically not a supportable public policy approach to the to the action and the markets are much much better otherwise they're just basically instituting rent control on on investing which is definitely not going to be the right way. Yeah so wait I was just lightning in thunder for a second. Can you hear that over there? Yeah. Oh is it lightning you said? Lightning. Okay fine. Not a tsunami not an earthquake. We're good right? So yeah so Eric to your question I would say we have to actually think more deeply in the following sense which is if you model you know the public sector as a platform and the private sector as the apps on that platform sometimes an app gets big enough that you just have to actually build a platform or become the platform right like you know Google was search and then it grew and grew and actually had to build its own platform right and like essentially Google you know with Chrome it kind of became something it's as Steve is aware it built the things and so what we have to do is we have to stop being reactive to Lena Khan or like Scott Wiener on the AI bill or things like that and we have to be proactive in the following way. A for every space that we're in we figure out what is the ideal set of laws. B we write model legislation for all 50 states and all 190 sovereign countries and AI can help with this but obviously it'll just give you a first trap it'll get you on base. C we build a sales team that goes down and knocks on the doors of those 50 states and 190 countries and of course there's subdivisions or cities and counties and all kinds of stuff both within and outside the US. Next we actually find politicians and of course you can rank before you go and knock on the doors you can rank that list by those that are the most pro-tech the most amenable to tech right. For example police in Colorado is friendly to like accepting Bitcoin for payments there or you have you know somebody who's posted about AI and they clearly you know their conversion with it and often you'll find some state senator or you know some governor like obviously there's McKellie before he became who he is today was a very pro-tech you know person in government in El Salvador. And so we identify all the pro-tech politicians around the world and in particular in this process small states are the friends of little tech because they're the ones who don't take anything for granted they want to build their economy and so on so forth and so we go to them we say here's a draft of a bill and then here's 10 CEOs or 10 founders or 10 investors or whatever 50 representing X billion dollars in AUM or Y billion dollars in revenue or some combined thing and if you pass this legislation then we will invest in your country right because then that that is now unlocked right now we can build speed of physics not permits right. I should write an article on this Elon Salvador okay Elon Salvador is what it sounds like which is the tie-up where in an American time zone Elon gets some space where he can build speed of physics not permits right all 20th century barriers go away you keep the common-sense stuff like you know Bash will not kill you know assault murder blah blah but are all those you don't have to sunset every law obviously right there's some laws that are just eternal laws but lots of 20th century regulations are just very stupid you know as IronPave said you know after the internet you have to kind of go back and look at a lot of laws and see if they still make sense right permitting laws this laws you know do they still make sense when you can build in different ways with robots or other things. So the answer is I don't think it would be a micro answer Eric which is it wouldn't just be like you know advising a con or a different con it's a macro answer of like go between countries essentially you know what it is rather than here's a flip rather than say oh you know how do we just how do we let them decide whether we're monopoly or not assume the US government was a monopoly the federal government and how do we build competition to that right how do we build jurisdictional competition how do we build choice because 96% of the world is on American and you know only and 50% is on blue even within the US you've got lots of jurisdictional choice so how do we do antitrust on that Maybe we'll wrap on that big idea Apologies Stephen this has been a fantastic conversation thanks so much thank you Thanks for listening to the A16Z podcast if you enjoyed the episode let us know by leaving a review at ratethispodcast.com slash A16Z We've got more great conversations coming your way see you next time


---

